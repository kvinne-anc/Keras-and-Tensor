{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Major_NN_Architecture_S.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "u4-s3-dnn"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.22.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kvinne-anc/Keras-and-Tensor/blob/main/Major_NN_Architecture_S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qelPnocpRkh"
      },
      "source": [
        "\n",
        "## Autograded Notebook (Canvas & CodeGrade)\n",
        "\n",
        "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
        "Instructions\n",
        "\n",
        "- **Download** this notebook as you would any other ipynb file \n",
        "- **Upload** to Google Colab or work locally (if you have that set-up)\n",
        "- **Delete** `raise NotImplementedError()`\n",
        "\n",
        "- **Write** your code in the `# YOUR CODE HERE` space\n",
        "\n",
        "\n",
        "- **Execute** the Test cells that contain assert statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
        "\n",
        "- **Save** your notebook when you are finished\n",
        "- **Download** as a ipynb file (if working in Colab)\n",
        "- **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnH1NrZVpRkk"
      },
      "source": [
        "# Major Neural Network Architectures Challenge\n",
        "## *Data Science Unit 4 Sprint 3 Challenge*\n",
        "\n",
        "In this sprint challenge, you'll explore some of the cutting edge of Deep Learning. This week we studied several famous neural network architectures: \n",
        "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Autoencoders. In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
        "\n",
        "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime locally, on AWS SageMaker, on Colab or on a comparable environment. If something is running longer, double check your approach!\n",
        "\n",
        "__*GridSearch:*__ CodeGrade will likely break if it is asked to run a gridsearch for a deep learning model (CodeGrade instances run on a single processor). So while you may choose to run a gridsearch locally to find the optimum hyper-parameter values for your model, please delete (or comment out) the gridsearch code and simply instantiate a model with the optimum parameter values to get the performance that you want out of your model prior to submission. \n",
        "\n",
        "\n",
        "## Challenge Objectives\n",
        "*You should be able to:*\n",
        "* <a href=\"#p1\">Part 1</a>: Train a LSTM classification model\n",
        "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for object detection\n",
        "* <a href=\"#p3\">Part 3</a>: Describe a use case for an autoencoder\n",
        "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI\n",
        "\n",
        "____\n",
        "\n",
        "# (CodeGrade) Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "3) If you have gridsearch code, now is when you either delete it or comment out that code so CodeGrade doesn't run it and crash. \n",
        "\n",
        "4) Read the directions in **Part 2** of this notebook for specific instructions on how to prep that section for CodeGrade.\n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5UwGRnJOmD4"
      },
      "source": [
        "<a id=\"p1\"></a>\n",
        "## Part 1 - LSTMs\n",
        "\n",
        "Use a LSTM to fit a multi-class classification model on Reuters news articles to distinguish topics of articles. The data is already encoded properly for use in a LSTM model. \n",
        "\n",
        "Your Tasks: \n",
        "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
        "- Name your model as `model`\n",
        "- Use a `single hidden layer`\n",
        "- Use `sparse_categorical_crossentropy` as your loss function\n",
        "- Use `accuracy` as your metric\n",
        "- Report your overall score and accuracy\n",
        "- Due to resource concerns on CodeGrade, `set your model's epochs=1`\n",
        "\n",
        "For reference, the LSTM code we used in class will be useful. \n",
        "\n",
        "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS-9ksWjoJit"
      },
      "source": [
        "# Import data (don't alter the code in this cell)\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "# Suppress some warnings from deprecated reuters.load_data\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=723812,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)\n",
        "\n",
        "# Due to limited computational resources on CodeGrade, take the following subsample \n",
        "train_size = 1000\n",
        "X_train = X_train[:train_size]\n",
        "y_train = y_train[:train_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLKqFh8DovaN",
        "outputId": "46992d7f-fd23-4c82-a01d-cc174afb1bf1"
      },
      "source": [
        "# Demo of encoding\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
        "print(f\"London is encoded as {word_index['london']} in the data\")\n",
        "print(\"Words are encoded as numbers in our dataset.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iran is encoded as 779 in the data\n",
            "London is encoded as 544 in the data\n",
            "Words are encoded as numbers in our dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IURmDeW5mDx",
        "outputId": "cc76619f-d781-4083-d495-061fa58a3b73"
      },
      "source": [
        "len(X_train[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRkrueyQ5tov",
        "outputId": "e69977ff-18c1-4c92-c260-6a8d32a23904"
      },
      "source": [
        "len(X_test[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qfTgY0xpRkn"
      },
      "source": [
        "# Imports (don't alter this code)\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "\n",
        "# DO NOT CHANGE THESE VALUES \n",
        "# Keras docs say that the + 1 is needed: https://keras.io/api/layers/core_layers/embedding/\n",
        "MAX_FEATURES = len(word_index.values()) + 1\n",
        "\n",
        "# maxlen is the length of each sequence (i.e. document length)\n",
        "MAXLEN = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYZfLz9cs2pH",
        "outputId": "ed0a3271-7be6-45e5-cd0c-870bac2a9e13"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bRZLa39vSDH",
        "outputId": "10e9145b-cad2-4664-9b97-2aee010a2d53"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spu6b91652nl",
        "outputId": "b69af31a-7d06-4f78-da03-77247f2bcce8"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2246,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlxQdA8855Fv",
        "outputId": "af00697d-6fc2-4743-c104-6928cccf46ad"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2246,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrFHwB4Ywpbs"
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Activation, Embedding, Bidirectional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "36031ab4b52ab8412c65a71e101baaf5",
          "grade": false,
          "grade_id": "cell-471d7f5819bebff6",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "aIX-Gyr9pRko"
      },
      "source": [
        "\n",
        "# Pre-process your data by creating sequences\n",
        "def print_text_from_seq(x):\n",
        "    # print('=================================================')\n",
        "    word_to_id = word_index\n",
        "   # word_to_id = {k:(v+index_from) for k,v in word_to_id.items()}\n",
        "    word_to_id[\"<PAD>\"] = 0\n",
        "    word_to_id[\"<START>\"] = 1\n",
        "    word_to_id[\"<UNK>\"] = 2\n",
        "    word_to_id[\"<UNUSED>\"] = 3\n",
        "\n",
        "    id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "  \n",
        "    print(f'Length = {len(x)}')\n",
        "    print(' '.join(id_to_word[id] for id in x ))\n",
        "    print('=================================================')\n",
        "\n",
        "# Save your transformed data to the same variable name:\n",
        "# example: X_train = some_transformation(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tAgBsN81ysH",
        "outputId": "b24b9f90-6319-49a9-8b30-7b3fcbeaa090"
      },
      "source": [
        "for i in range(0, 6):\n",
        "    print(X_train[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 248, 409, 166, 265, 1537, 1662, 8, 24, 4, 1222, 2771, 7, 227, 236, 40, 85, 944, 10, 531, 176, 8, 4, 176, 1613, 24, 1662, 297, 5157, 6, 10, 103, 5, 231, 215, 8, 7, 2889, 6, 10, 1202, 69, 4, 1222, 329, 2771, 24, 944, 23, 944, 1662, 40, 2509, 1592, 907, 69, 4, 113, 997, 762, 2539, 7, 227, 236, 17, 12]\n",
            "[1, 4665, 1183, 413, 381, 7, 1134, 1664, 62, 729, 7, 4, 121, 273, 93, 109, 28, 2115, 72, 11, 428, 4, 387, 989, 558, 3956, 8, 7, 25, 1213, 427, 1969, 223, 4, 213, 5, 387, 580, 8, 1145, 413, 62, 410, 451, 18, 428, 7, 4, 121, 6, 3106, 19, 11, 428, 9, 1283, 317, 65, 413, 138, 59, 12, 11, 428, 6, 6118, 63, 11, 4, 3956, 8, 3640, 1183, 413, 202, 251, 18, 428, 6, 546, 19, 11, 428, 9, 317, 65, 413, 7, 4, 1721, 427, 409, 7145, 138, 19, 19, 11, 428, 6, 3843, 70, 11, 4, 135, 5, 137, 317, 1833, 542, 9, 7145, 413, 138, 72, 47, 11, 428, 6, 19, 5106, 19, 16, 8, 17, 12]\n",
            "[1, 56, 14065, 65, 9, 249, 149, 8, 4, 347, 5, 25, 65, 9, 249, 282, 333, 27, 258, 20, 6, 644, 59, 11, 15, 22, 653, 32, 11, 15, 257, 28, 29, 153, 105, 519, 6, 42, 1436, 7233, 14065, 8, 16, 40, 282, 5, 32, 47, 11, 428, 5, 65, 9, 659, 249, 3264, 9, 934, 32, 35, 1396, 983, 5, 659, 249, 7, 788, 388, 20, 324, 56, 26262, 705, 149, 40, 342, 282, 5, 2639, 18, 428, 5, 65, 9, 19, 59, 10637, 5, 659, 249, 31, 10, 143, 347, 5, 32, 32, 11, 15, 14065, 8, 17, 12]\n",
            "[1, 346, 273, 94, 187, 53, 74, 472, 26, 14, 46, 19, 124, 15, 39, 74, 32, 6582, 18, 14, 46, 61, 6097, 18, 1730, 1668, 32, 11, 14, 996, 12, 11, 123, 346, 39, 235, 627, 276, 5, 19, 19, 11, 15, 17, 12]\n",
            "[1, 1228, 81, 8, 261, 524, 10, 384, 292, 322, 5, 4, 49, 31, 10, 323, 5, 1400, 103, 450, 16, 8, 1400, 381, 69, 928, 20, 5, 1228, 80, 480, 10, 334, 116, 9, 100, 766, 157, 7, 4, 29, 31, 4, 1395, 5, 4, 587, 1400, 33, 2356, 6, 219, 767, 15, 10, 67, 6, 4, 1004, 1228, 261, 17, 12]\n",
            "[1, 67, 416, 170, 54, 1223, 27, 356, 697, 81, 13161, 215, 8, 4, 116, 23, 3283, 8, 3522, 12484, 42, 559, 31, 1009, 716, 1578, 1838, 24, 16, 535, 45, 2746, 4, 834, 1802, 117, 4, 326, 2349, 347, 267, 21, 186, 828, 9668, 50, 40, 63, 61, 11, 79, 335, 34, 238, 28, 722, 19, 63, 233, 12, 63, 9668, 826, 195, 5, 313, 7135, 27569, 8, 36, 114, 45, 594, 21, 4, 9148, 5, 4, 116, 58, 21, 185, 4, 166, 41, 668, 6, 888, 16, 12484, 8, 24, 184, 9668, 34, 238, 28, 210, 492, 15, 10, 67, 28, 4, 216, 5, 4, 615, 416, 25, 1020, 24, 314, 289, 5, 266, 186, 1423, 1014, 25, 347, 9668, 8, 25, 390, 98, 186, 41, 1740, 215, 1423, 5, 296, 6, 124, 26, 10, 67, 28, 24, 96, 9668, 114, 1070, 10, 80, 96, 7, 4, 456, 22581, 12484, 8, 1578, 553, 25, 89, 186, 862, 13, 4, 2050, 362, 907, 6, 19, 279, 15, 10, 67, 22, 19, 119, 15, 21, 4, 17213, 36, 8, 16, 2351, 25, 448, 5692, 6, 19, 512, 15, 10, 67, 22, 19, 482, 15, 7, 788, 215, 8, 4, 7923, 2050, 362, 218, 1043, 922, 159, 917, 4, 182, 40, 3020, 22, 158, 6, 352, 20, 117, 4, 54, 142, 206, 267, 21, 186, 90, 67, 8, 5856, 19657, 42, 559, 31, 4296, 3367, 9, 111, 4, 182, 23, 133, 6, 351, 815, 28, 102, 6, 352, 20, 117, 4, 225, 142, 206, 36, 8, 12484, 8, 4, 688, 150, 10, 67, 116, 58, 2304, 11, 15, 135, 41, 30, 10, 7096, 13, 356, 697, 4, 1697, 9, 387, 49, 41, 286, 276, 4358, 172, 10, 1787, 218, 9, 3685, 419, 538, 1469, 36, 8, 356, 697, 40, 432, 55, 6709, 6, 30, 126, 2482, 15980, 30377, 692, 5, 25, 595, 36, 8, 28383, 21911, 4611, 195, 5, 29555, 65, 111, 24315, 50, 1043, 10, 124, 47, 20, 310, 7, 9668, 8, 54, 121, 356, 8568, 116, 34, 8197, 3283, 17, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhFAQLFT3J1P",
        "outputId": "35b3941f-f803-46e3-9e1b-ab011cac97a3"
      },
      "source": [
        "print('Pad Sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(X_train, maxlen=MAXLEN)\n",
        "x_test = sequence.pad_sequences(X_test, maxlen=MAXLEN)\n",
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad Sequences (samples x time)\n",
            "x_train shape:  (1000, 200)\n",
            "x_test shape:  (2246, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cef4a5ae6ec56bee0d3121c7d8d37f3e",
          "grade": true,
          "grade_id": "cell-b46c98c26266363a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "sNIgz0UdpRko"
      },
      "source": [
        "# Visible tests\n",
        "assert x_train.shape[1] == MAXLEN, \"Your train input sequences are the wrong length. Did you use the sequence import?\"\n",
        "assert x_test.shape[1] == MAXLEN, \"Your test input sequences are the wrong length. Did you use the sequence import?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcwXLi25pRkp"
      },
      "source": [
        "### Create your model\n",
        "\n",
        "Make sure to follow these instructions (also listed above):\n",
        "- Name your model as `model`\n",
        "- Use a `single hidden layer`\n",
        "- Use `sparse_categorical_crossentropy` as your loss function\n",
        "- Use `accuracy` as your metric\n",
        "\n",
        "**Additional considerations**\n",
        "\n",
        "The number of nodes in your output layer should be equal to the number of **unique** values in the sequences you are training and testing on. For this text, that value is equal to 46.\n",
        "\n",
        "- Set the number of nodes in your output layer equal to 46"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwXQPihmA3Td",
        "outputId": "d05c16aa-1903-432d-bb4e-b66e85205a57"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_FEATURES, 46))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(46)))\n",
        "model.add(Dense(46, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, None, 46)          1425080   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, None, 46)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 92)                34224     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 46)                4278      \n",
            "=================================================================\n",
            "Total params: 1,463,582\n",
            "Trainable params: 1,463,582\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrY8pgu5CaO7"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cc18fbac87183e4e19e0342541d5684b",
          "grade": false,
          "grade_id": "cell-5e7ea9089f827793",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "jLf_8wWKpRkp"
      },
      "source": [
        "# Build and complie your model here\n",
        "#from tensorflow.keras.layers import Dropout\n",
        "\n",
        "#model = Sequential()\n",
        "#model.add(Embedding(MAX_FEATURES, 46))  \n",
        "#model.add(Dropout(0.1))\n",
        "#model.compile(loss='sparse_categorical_crossentropy',\n",
        " #             optimizer='adam', \n",
        "  #            metrics=['accuracy'])\n",
        "#model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ff2e025e7744c0524ecebcb854ae632d",
          "grade": true,
          "grade_id": "cell-54f4676c642d2c94",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9_MOLWrnpRkp"
      },
      "source": [
        "# Visible Test\n",
        "assert model.get_config()[\"layers\"][1][\"class_name\"] == \"Embedding\", \"Layer 1 should be an Embedding layer.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cc9bb4e19f4d22eb6a243d76024fb637",
          "grade": true,
          "grade_id": "cell-974465c65fe51083",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ohCMiBb5pRkp"
      },
      "source": [
        "# Hidden Test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34P--F9fpRkq"
      },
      "source": [
        "### Fit your model\n",
        "\n",
        "Now, fit the model that you built and compiled in the previous cells. Remember to set your `epochs=1`! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "id": "_QVSlFEAqWJM",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "214ed02cdf6fe3f25483d81c2f4dd09c",
          "grade": false,
          "grade_id": "cell-10c20c87933d059c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "6647ce1f-3dba-425d-dfbd-0a8e80135410"
      },
      "source": [
        "# Fit your model here\n",
        "# REMEMBER to set epochs=1\n",
        "output = model.fit(x_train, \n",
        "                   y_train, \n",
        "                   batch_size=46, \n",
        "                   epochs=1, \n",
        "                   validation_data=(x_test, y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 11s 341ms/step - loss: 3.6927 - accuracy: 0.2663 - val_loss: 2.5609 - val_accuracy: 0.3664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ca6a93fe03cb86e1d3ba3d38fc848102",
          "grade": true,
          "grade_id": "cell-277a7dc0b08b9a29",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ZQC2z4SApRkq"
      },
      "source": [
        "# Visible Test \n",
        "n_epochs = len(model.history.history[\"loss\"])\n",
        "assert n_epochs == 1, \"Verify that you set epochs to 1.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5035264cce6916dab4735e61ab5a92a0",
          "grade": false,
          "grade_id": "cell-e46402041c52cd24",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "tMoAOydipRkq"
      },
      "source": [
        "## Sequence Data Question\n",
        "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "466921cbc36892fb12aa9a3f0c2424a3",
          "grade": true,
          "grade_id": "cell-92a7ebc76ad66f05",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "2ntct52YpRkr"
      },
      "source": [
        "pad_sequences method deals with the variable length issue. \n",
        "It ensures that all the sequenceses are the same length by adding place holders at the beginning or the end depending on 'pre' or 'post' argument. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1162a5c137e05e13d9c1275bf89709c2",
          "grade": false,
          "grade_id": "cell-a7a697b125edb2b7",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "9ZMyDyNqpRkr"
      },
      "source": [
        "## RNNs versus LSTMs\n",
        "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e88cf9a290290a182ca8381c5055b218",
          "grade": true,
          "grade_id": "cell-bfe45496d78d39bb",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "OR_Lk4DxpRkr"
      },
      "source": [
        "LSTM gives us more controlability over the flow and mix of inputs per trained weights "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "72cdfd02468a598b328fef9d0fb2c449",
          "grade": false,
          "grade_id": "cell-ca70eabc807f8f52",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "Jb0x7Uv-pRkr"
      },
      "source": [
        "## RNN / LSTM Use Cases\n",
        "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "91b3a655469df8a2d64e7c7c0c0aed02",
          "grade": true,
          "grade_id": "cell-eeaef2336d124b88",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "WiT_poBvpRkr"
      },
      "source": [
        "RNN/LSTM Use Cases: \n",
        "Speech recognition (Siri/Cortana),\n",
        "Text autofill,\n",
        "Translation,\n",
        "Stock Prices, \n",
        "DNA sequencing\n",
        "\n",
        "RNN and LSTM are very useful in processing textual and speech data because each word in a sequence is dependent upon the previous word. They use the context of each word... ie. to predict one word, the word before it is already providing a great deal of information as to what words are likely to follow. LSTM's are generally preferrable to RNNs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz0LCZd_O4IG"
      },
      "source": [
        "<a id=\"p2\"></a>\n",
        "## Part 2- CNNs\n",
        "\n",
        "### Find the Frog\n",
        "\n",
        "Time to play \"find the frog!\" Use Keras and [ResNet50v2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2) (pre-trained) to detect which of the images with the `frog_images` subdirectory has a frog in it.\n",
        "\n",
        "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKCnunW0pRks"
      },
      "source": [
        "The skimage function below will help you read in all the frog images into memory at once. You should use the preprocessing functions that come with ResnetV2, and you should also resize the images using scikit-image.\n",
        "\n",
        "### Reading in the images\n",
        "\n",
        "The code in the following cell will download the images to your notebook (either in your local Jupyter notebook or in Google colab)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si5YfNqS50QU"
      },
      "source": [
        "### Run ResNet50v2\n",
        "\n",
        "Your goal is to validly run ResNet50v2 on the input images - don't worry about tuning or improving the model. You can print out or view the predictions in any way you see fit. In order to receive credit, you need to have made predictions at some point in the following cells.\n",
        "\n",
        "*Hint* - ResNet 50v2 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
        "\n",
        "**Autograded tasks**\n",
        "\n",
        "* Instantiate your ResNet 50v2 and save to a variable named `resnet_model`\n",
        "\n",
        "**Other tasks**\n",
        "* Re-size your images\n",
        "* Use `resnet_model` to predict if each image contains a frog\n",
        "* Decode your predictions\n",
        "* Hint: the lesson on CNNs will have some helpful code\n",
        "\n",
        "**Stretch goals***\n",
        "* Check for other things such as fish\n",
        "* Print out the image with its predicted label\n",
        "* Wrap everything nicely in well documented functions\n",
        "\n",
        "## Important note!\n",
        "\n",
        "To increase the chances that your notebook will run in CodeGrade, when you **submit** your notebook:\n",
        "\n",
        "* comment out the code where you load the images\n",
        "* comment out the code where you make the predictions\n",
        "* comment out any plots or image displays you create\n",
        "\n",
        "**MAKE SURE YOUR NOTEBOOK RUNS COMPLETELY BEFORE YOU SUBMIT!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-clIm5hCpRks"
      },
      "source": [
        "# Prep to import images (don't alter the code in this cell)\n",
        "import urllib.request\n",
        "\n",
        "# Text file of image URLs\n",
        "text_file = \"https://raw.githubusercontent.com/LambdaSchool/data-science-canvas-images/main/unit_4/sprint_challenge_files/frog_image_url.txt\"\n",
        "data = urllib.request.urlopen(text_file)\n",
        "\n",
        "# Create list of image URLs\n",
        "url_list = [] \n",
        "for line in data:\n",
        "    url_list.append(line.decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whIqEWR236Af",
        "outputId": "ff7ccb2f-cb18-43cc-904b-855f64963ed2"
      },
      "source": [
        "# Import images (don't alter the code in this cell)\n",
        "\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize \n",
        "\n",
        "# instantiate list to hold images\n",
        "image_list = []\n",
        "\n",
        "### UNCOMMENT THE FOLLOWING CODE TO LOAD YOUR IMAGES\n",
        "\n",
        "#loop through URLs and load each image\n",
        "for url in url_list:\n",
        "    image_list.append(imread(url))\n",
        "\n",
        "## UNCOMMENT THE FOLLOWING CODE TO VIEW AN EXAMPLE IMAGE SIZE\n",
        "#What is an \"image\"?\n",
        "print(type(image_list[0]), end=\"\\n\\n\")\n",
        "\n",
        "print(\"Each of the Images is a Different Size\")\n",
        "print(image_list[0].shape)\n",
        "print(image_list[1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "\n",
            "Each of the Images is a Different Size\n",
            "(2137, 1710, 3)\n",
            "(3810, 2856, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaT07ddW3nHz"
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2 # <-- pre-trained model \n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3oLz5XCQ0i4"
      },
      "source": [
        "resnet_model = tf.keras.applications.ResNet50V2(\n",
        "    include_top=True, weights='imagenet', input_tensor=None,\n",
        "    input_shape=None, pooling=None, classes=1000,\n",
        "    classifier_activation='softmax'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y35S0QrRPhj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "00c7d152b14a85442baaad9b9fcbbe15",
          "grade": false,
          "grade_id": "cell-2715a95f2bcdf3f8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "rW3MkHMkpRku"
      },
      "source": [
        "# Code from the CNN lecture might come in handy here! \n",
        "#Instantiate your ResNet 50v2 and save to a variable named resnet_model\n",
        "\n",
        "def process_img_path(img_path):\n",
        "  return image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "def img_recognition_pretrain(img):\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "  model = ResNet50(weights='imagenet')\n",
        "  features = model.predict(x)\n",
        "  results = decode_predictions(features, top=4)[0]\n",
        "  print(results)\n",
        "  for entry in results:\n",
        "    if entry[1] == 'bullfrog':\n",
        "      return entry[2]\n",
        "  return 0.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfBO2Z0KW3qO"
      },
      "source": [
        "#Genuinely no idea whatsoever and I'm out of time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "yOSKgHMOMiMp",
        "outputId": "2577d772-8c32-463b-bf64-7ea144e5a857"
      },
      "source": [
        "# Define the batch size:\n",
        "batch_size=32\n",
        "\n",
        "# Define the train and validation generators: \n",
        "train = train_datagen.flow_from_directory(\n",
        "    image_list,\n",
        "    target_size=(224, 224),\n",
        "    classes=['bullfrog','tree_frog','tailed_frog'],\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        "    )\n",
        "\n",
        "val = valid_datagen.flow_from_directory(\n",
        "    directory=image_list,\n",
        "    target_size=(224, 224),\n",
        "    classes=['bullfrog','tree_frog','tailed_frog'],\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-3faf5a4fce37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bullfrog'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tree_frog'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tailed_frog'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdirpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             results.append(\n\u001b[1;32m    130\u001b[0m                 pool.apply_async(_list_valid_filenames_in_directory,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdirpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             results.append(\n\u001b[1;32m    130\u001b[0m                 pool.apply_async(_list_valid_filenames_in_directory,\n",
            "\u001b[0;32m/usr/lib/python3.7/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdiscarded\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     ends with a separator.\"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duOZ7vLDMiG3"
      },
      "source": [
        "#Re-size your images\n",
        "#Use resnet_model to predict if each image contains a frog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "dc052ce43e9c6139f9049a72613c53cb",
          "grade": true,
          "grade_id": "cell-6e0982cb9f7775ef",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "qUsTo4YupRku"
      },
      "source": [
        "# Visible test\n",
        "assert resnet_model.get_config()[\"name\"] == \"resnet50v2\", \"Did you instantiate the resnet model?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "XEuhvSu7O5Rf",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "07da5c698aa6b4bfc985abf74be530d0",
          "grade": false,
          "grade_id": "cell-98f795ea1478ba74",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        }
      },
      "source": [
        "<a id=\"p3\"></a>\n",
        "## Part 3 - Autoencoders\n",
        "\n",
        "**Describe a use case for an autoencoder given that an autoencoder tries to predict its own input.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b9def07acfd8d9a0bb2fb9b3a9d20170",
          "grade": true,
          "grade_id": "cell-1ec34a8c8251db51",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "4BRmi1TVpRku"
      },
      "source": [
        "Reverse image search, \n",
        "recommendation systems - content based filtering, \n",
        "\n",
        "Autoencoders, in my simplified interpretation, fill in blanks of the inputs, rather than the other way around... ie. search suggestions, mispelled words, alternative wording, related material or concepts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "626zYgjkO7Vq"
      },
      "source": [
        "<a id=\"p4\"></a>\n",
        "## Part 4 - More..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "__lDWfcUO8oo",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "061b43713725ca6955ee708b4495d0df",
          "grade": false,
          "grade_id": "cell-75a20bfb51f81e3b",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        }
      },
      "source": [
        "**Answer the following questions, with a target audience of a fellow Data Scientist:**\n",
        "\n",
        "- What do you consider your strongest area as a Data Scientist?\n",
        "- What area of Data Science would you most like to learn more about, and why?\n",
        "- Where do you think Data Science will be in 5 years?\n",
        "\n",
        "A few sentences per answer is fine - only elaborate if time allows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7e4b53bf4d823ee49c9fcb0e91c0dae3",
          "grade": true,
          "grade_id": "cell-7133ec302afe51d8",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "sKFeVAn-pRkv"
      },
      "source": [
        "- Strongest: I am good at doing the research to figure out what data to join in and I am particularly good at working with geospatial data, which I really enjoy and taught myself while working on the waterpump challenge.\n",
        "- I would like to learn more about real world use cases. I wnat to know how to use this in the field of biotech, genetics, biopharma, really anything more interesting than these largely boring datasets we look at. I feel like this stuff could be really interesting and I know it's useful but I really can't connect the dots between the technical parts and the potential applications when the esubject material that I am applying it to is so mundane that I can't understand why anyone would bother (see lecture on creating classes and objects for polo shirt colors/used car inventory) \n",
        "- Hopefully in 5 years I will have had the time to re-learn everything from Unit 3 and 4 and found a way to take the interesting elements and really do something interesting with them that furthers our understanding of biologicalprocesses/ecosystems/evolution/molecular structure/DNA/longevity/ and hopefully I will have managed to escape the hell that would be applying this to consumer insights/entertainment/tv/music/HR (my personall hell).\n",
        "- I think I peaked in Unit 2 and the structural shift threw me off so I very much intend to go learn a ton of this again. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hoqe3mM_Mtc"
      },
      "source": [
        "## Congratulations! \n",
        "\n",
        "Thank you for your hard work, and [congratulations](https://giphy.com/embed/26xivLqkv86uJzqWk)!!! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
      ]
    }
  ]
}