{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "NN_KerasModel_S.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ib9bpc-ro3AV",
        "QGa9jEI-o3AW",
        "6XiqmgPao3AX"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kvinne-anc/Keras-and-Tensor/blob/main/NN_KerasModel_S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17x_zw9Qo3AK"
      },
      "source": [
        "\n",
        "## Autograded Notebook (Canvas & CodeGrade)\n",
        "\n",
        "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
        "Instructions\n",
        "\n",
        "- **Download** this notebook as you would any other ipynb file \n",
        "- **Upload** to Google Colab or work locally (if you have that set-up)\n",
        "- **Delete** `raise NotImplementedError()`\n",
        "\n",
        "- **Write** your code in the `# YOUR CODE HERE` space\n",
        "\n",
        "\n",
        "- **Execute** the Test cells that contain assert statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
        "\n",
        "- **Save** your notebook when you are finished\n",
        "- **Download** as a ipynb file (if working in Colab)\n",
        "- **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te_SK43co3AP"
      },
      "source": [
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron (i.e. Neural Network)\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)\n",
        "\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a2d017ba3200be3890c0b67eda283c48",
          "grade": false,
          "grade_id": "cell-621a8b86bacf295a",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "Yn3mCB6No3AQ"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Defining Neural Networks \n",
        "\n",
        "Write *your own* definitions for the following terms:\n",
        "\n",
        "- **Neuron:**\n",
        "\n",
        "- **Input Layer:** \n",
        "\n",
        "- **Hidden Layer:** \n",
        "\n",
        "- **Output Layer:**\n",
        "\n",
        "- **Activation:** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7233c31461609b21a7fc2651afb12632",
          "grade": true,
          "grade_id": "cell-6adae65226f09553",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "vD7v0kkHo3AQ"
      },
      "source": [
        "Neuron - A neuron is akin to a biological neuron. It is a connection process, defined by a mathematical function, which receives information and processes it to return a conclusion. \n",
        "\n",
        "Input layer - the first layer of the neuron. It is like the receptor, which takes in the initial data. \n",
        "\n",
        "Hidden layer - this is like a synapse. It it the layer which does the bulk of the processing and the way we define it (the parameters, activations, etc. that we choose) determines this \"thought process\".\n",
        "\n",
        "Output layer - this layer returns the final result of our neuron's 'thought process'. \n",
        "\n",
        "Activation - The activation function determines how our neuron 'thinks'; the elements that we choose to use are responsible for for weighing biases and determining which elemnts and relationships between these elements should be important and which are less so and which are white noise. It gives our neuron a scope of how to attack a problem, or how to find the most relevant connections between the data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "10aa095d3db59bfe47f9823cfd62f1ef",
          "grade": false,
          "grade_id": "cell-d64f1de9e9458dc7",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "1A7JHz3wo3AR"
      },
      "source": [
        "- `Explain` how Back-propagation works \n",
        "- `Explain` how Gradient Descent works (mention the learning rate)\n",
        "- `Explain` how Back-propagation and Gradient Descent are related   \n",
        "\n",
        "Use your own words, but feel free to reference external materials for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ceb3f64a4b1b18346decf75c8f5567d2",
          "grade": true,
          "grade_id": "cell-cef20b23d4e0b056",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "FfOJnC2-o3AR"
      },
      "source": [
        "- Back propagation takes the error between the predicted value and the real of the output layer as an error of the weights and biases (gradient of the loss function) in the original calculation and feeds it back through the network with the goal of reducing the error by adjusting the weights and biases, taking the new information into account. \n",
        "\n",
        "- Gradient descent an optimization algorithm that helps us find the slope that is the quickest route from where we are to where we are trying to be. The gradient optimization algorithim helps to sort error and optimal value. The learning rate is the speed, or grade/unit of measure, by which the algorithm changes with each new iteration. If the algorithm only needs a small tweak but we set the rate too high then it jumps all over and won't hit the target, too small and it will take too long to get there. \n",
        "\n",
        "- Backpropagation method finds the gradient which  and the gradient descent uses the gradient to 'learn' and find the best set of parameters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e040f3ddce6eb34b017f0eb685b202e6",
          "grade": false,
          "grade_id": "cell-e013d19857352d79",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "fU6Wo58-o3AR"
      },
      "source": [
        "Remember our Simple Perceptron Class from Monday. \n",
        "\n",
        "- Describe the process of making a prediction, i.e. how do you go from inputs to outputs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d746de6391012340f8548821850a621c",
          "grade": true,
          "grade_id": "cell-53c7cc36db9d7983",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "nc1v8quho3AR"
      },
      "source": [
        "The process of making a prediction is straightforward enough in theory. We start with a dataset, split it into train and test, or even a simple x and y. We can define a function and create a model, define the type of of model (sequential/functional) and add hidden layers and define the parameters that we want to test and define the dimensions of the output layer. The we run the model and go from there. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbkzK-gFo3AR"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. Simple Perceptron\n",
        "\n",
        "In this question, you will build two neural networks using `Keras`. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI7_3P3go3AS"
      },
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNIxGyfno3AS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf6cf6e-9bc3-4f93-905d-4c2f88aa3143"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAaM0H1b5_1Q",
        "outputId": "026637c8-dfb6-4de1-b9ef-9b3c9cd4dc6a"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.76405235,  0.40015721],\n",
              "       [ 0.97873798,  2.2408932 ],\n",
              "       [ 1.86755799, -0.97727788],\n",
              "       [ 0.95008842, -0.15135721],\n",
              "       [-0.10321885,  0.4105985 ],\n",
              "       [ 0.14404357,  1.45427351],\n",
              "       [ 0.76103773,  0.12167502],\n",
              "       [ 0.44386323,  0.33367433],\n",
              "       [ 1.49407907, -0.20515826],\n",
              "       [ 0.3130677 , -0.85409574],\n",
              "       [-2.55298982,  0.6536186 ],\n",
              "       [ 0.8644362 , -0.74216502],\n",
              "       [ 2.26975462, -1.45436567],\n",
              "       [ 0.04575852, -0.18718385],\n",
              "       [ 1.53277921,  1.46935877],\n",
              "       [ 0.15494743,  0.37816252],\n",
              "       [-0.88778575, -1.98079647],\n",
              "       [-0.34791215,  0.15634897],\n",
              "       [ 1.23029068,  1.20237985],\n",
              "       [-0.38732682, -0.30230275],\n",
              "       [-1.04855297, -1.42001794],\n",
              "       [-1.70627019,  1.9507754 ],\n",
              "       [-0.50965218, -0.4380743 ],\n",
              "       [-1.25279536,  0.77749036],\n",
              "       [-1.61389785, -0.21274028],\n",
              "       [-0.89546656,  0.3869025 ],\n",
              "       [-0.51080514, -1.18063218],\n",
              "       [-0.02818223,  0.42833187],\n",
              "       [ 0.06651722,  0.3024719 ],\n",
              "       [-0.63432209, -0.36274117],\n",
              "       [-0.67246045, -0.35955316],\n",
              "       [-0.81314628, -1.7262826 ],\n",
              "       [ 0.17742614, -0.40178094],\n",
              "       [-1.63019835,  0.46278226],\n",
              "       [-0.90729836,  0.0519454 ],\n",
              "       [ 0.72909056,  0.12898291],\n",
              "       [ 1.13940068, -1.23482582],\n",
              "       [ 0.40234164, -0.68481009],\n",
              "       [-0.87079715, -0.57884966],\n",
              "       [-0.31155253,  0.05616534],\n",
              "       [-1.16514984,  0.90082649],\n",
              "       [ 0.46566244, -1.53624369],\n",
              "       [ 1.48825219,  1.89588918],\n",
              "       [ 1.17877957, -0.17992484],\n",
              "       [-1.07075262,  1.05445173],\n",
              "       [-0.40317695,  1.22244507],\n",
              "       [ 0.20827498,  0.97663904],\n",
              "       [ 0.3563664 ,  0.70657317],\n",
              "       [ 0.01050002,  1.78587049],\n",
              "       [ 0.12691209,  0.40198936],\n",
              "       [ 1.8831507 , -1.34775906],\n",
              "       [-1.270485  ,  0.96939671],\n",
              "       [-1.17312341,  1.94362119],\n",
              "       [-0.41361898, -0.74745481],\n",
              "       [ 1.92294203,  1.48051479],\n",
              "       [ 1.86755896,  0.90604466],\n",
              "       [-0.86122569,  1.91006495],\n",
              "       [-0.26800337,  0.8024564 ],\n",
              "       [ 0.94725197, -0.15501009],\n",
              "       [ 0.61407937,  0.92220667],\n",
              "       [ 0.37642553, -1.09940079],\n",
              "       [ 0.29823817,  1.3263859 ],\n",
              "       [-0.69456786, -0.14963454],\n",
              "       [-0.43515355,  1.84926373],\n",
              "       [ 0.67229476,  0.40746184],\n",
              "       [-0.76991607,  0.53924919],\n",
              "       [-0.67433266,  0.03183056],\n",
              "       [-0.63584608,  0.67643329],\n",
              "       [ 0.57659082, -0.20829876],\n",
              "       [ 0.39600671, -1.09306151],\n",
              "       [-1.49125759,  0.4393917 ],\n",
              "       [ 0.1666735 ,  0.63503144],\n",
              "       [ 2.38314477,  0.94447949],\n",
              "       [-0.91282223,  1.11701629],\n",
              "       [-1.31590741, -0.4615846 ],\n",
              "       [-0.06824161,  1.71334272],\n",
              "       [-0.74475482, -0.82643854],\n",
              "       [-0.09845252, -0.66347829],\n",
              "       [ 1.12663592, -1.07993151],\n",
              "       [-1.14746865, -0.43782004],\n",
              "       [-0.49803245,  1.92953205],\n",
              "       [ 0.94942081,  0.08755124],\n",
              "       [-1.22543552,  0.84436298],\n",
              "       [-1.00021535, -1.5447711 ],\n",
              "       [ 1.18802979,  0.31694261],\n",
              "       [ 0.92085882,  0.31872765],\n",
              "       [ 0.85683061, -0.65102559],\n",
              "       [-1.03424284,  0.68159452],\n",
              "       [-0.80340966, -0.68954978],\n",
              "       [-0.4555325 ,  0.01747916],\n",
              "       [-0.35399391, -1.37495129],\n",
              "       [-0.6436184 , -2.22340315],\n",
              "       [ 0.62523145, -1.60205766],\n",
              "       [-1.10438334,  0.05216508],\n",
              "       [-0.739563  ,  1.5430146 ],\n",
              "       [-1.29285691,  0.26705087],\n",
              "       [-0.03928282, -1.1680935 ],\n",
              "       [ 0.52327666, -0.17154633],\n",
              "       [ 0.77179055,  0.82350415],\n",
              "       [ 2.16323595,  1.33652795],\n",
              "       [-0.36918184, -0.23937918],\n",
              "       [ 1.0996596 ,  0.65526373],\n",
              "       [ 0.64013153, -1.61695604],\n",
              "       [-0.02432612, -0.73803091],\n",
              "       [ 0.2799246 , -0.09815039],\n",
              "       [ 0.91017891,  0.31721822],\n",
              "       [ 0.78632796, -0.4664191 ],\n",
              "       [-0.94444626, -0.41004969],\n",
              "       [-0.01702041,  0.37915174],\n",
              "       [ 2.25930895, -0.04225715],\n",
              "       [-0.955945  , -0.34598178],\n",
              "       [-0.46359597,  0.48148147],\n",
              "       [-1.54079701,  0.06326199],\n",
              "       [ 0.15650654,  0.23218104],\n",
              "       [-0.59731607, -0.23792173],\n",
              "       [-1.42406091, -0.49331988],\n",
              "       [-0.54286148,  0.41605005],\n",
              "       [-1.15618243,  0.7811981 ],\n",
              "       [ 1.49448454, -2.06998503],\n",
              "       [ 0.42625873,  0.67690804],\n",
              "       [-0.63743703, -0.39727181],\n",
              "       [-0.13288058, -0.29779088],\n",
              "       [-0.30901297, -1.67600381],\n",
              "       [ 1.15233156,  1.07961859],\n",
              "       [-0.81336426, -1.46642433],\n",
              "       [ 0.52106488, -0.57578797],\n",
              "       [ 0.14195316, -0.31932842],\n",
              "       [ 0.69153875,  0.69474914],\n",
              "       [-0.72559738, -1.38336396],\n",
              "       [-1.5829384 ,  0.61037938],\n",
              "       [-1.18885926, -0.50681635],\n",
              "       [-0.59631404, -0.0525673 ],\n",
              "       [-1.93627981,  0.1887786 ],\n",
              "       [ 0.52389102,  0.08842209],\n",
              "       [-0.31088617,  0.09740017],\n",
              "       [ 0.39904635, -2.77259276],\n",
              "       [ 1.95591231,  0.39009332],\n",
              "       [-0.65240858, -0.39095338],\n",
              "       [ 0.49374178, -0.11610394],\n",
              "       [-2.03068447,  2.06449286],\n",
              "       [-0.11054066,  1.02017271],\n",
              "       [-0.69204985,  1.53637705],\n",
              "       [ 0.28634369,  0.60884383],\n",
              "       [-1.04525337,  1.21114529],\n",
              "       [ 0.68981816,  1.30184623],\n",
              "       [-0.62808756, -0.48102712],\n",
              "       [ 2.3039167 , -1.06001582],\n",
              "       [-0.1359497 ,  1.13689136],\n",
              "       [ 0.09772497,  0.58295368],\n",
              "       [-0.39944903,  0.37005589],\n",
              "       [-1.30652685,  1.65813068],\n",
              "       [-0.11816405, -0.6801782 ],\n",
              "       [ 0.66638308, -0.46071979],\n",
              "       [-1.33425847, -1.34671751],\n",
              "       [ 0.69377315, -0.15957344],\n",
              "       [-0.13370156,  1.07774381],\n",
              "       [-1.12682581, -0.73067775],\n",
              "       [-0.38487981,  0.09435159],\n",
              "       [-0.04217145, -0.28688719],\n",
              "       [-0.0616264 , -0.10730528],\n",
              "       [-0.71960439, -0.81299299],\n",
              "       [ 0.27451636, -0.89091508],\n",
              "       [-1.15735526, -0.31229225],\n",
              "       [-0.15766702,  2.2567235 ],\n",
              "       [-0.70470028,  0.94326072],\n",
              "       [ 0.74718833, -1.18894496],\n",
              "       [ 0.77325298, -1.18388064],\n",
              "       [-2.65917224,  0.60631952],\n",
              "       [-1.75589058,  0.45093446],\n",
              "       [-0.6840109 ,  1.6595508 ],\n",
              "       [ 1.0685094 , -0.4533858 ],\n",
              "       [-0.68783761, -1.2140774 ],\n",
              "       [-0.44092263, -0.2803555 ],\n",
              "       [-0.36469354,  0.15670386],\n",
              "       [ 0.5785215 ,  0.34965446],\n",
              "       [-0.76414392, -1.43779147],\n",
              "       [ 1.36453185, -0.68944918],\n",
              "       [-0.6522936 , -0.52118931],\n",
              "       [-1.84306955, -0.477974  ],\n",
              "       [-0.47965581,  0.6203583 ],\n",
              "       [ 0.69845715,  0.00377089],\n",
              "       [ 0.93184837,  0.33996498],\n",
              "       [-0.01568211,  0.16092817],\n",
              "       [-0.19065349, -0.39484951],\n",
              "       [-0.26773354, -1.12801133],\n",
              "       [ 0.28044171, -0.99312361],\n",
              "       [ 0.84163126, -0.24945858],\n",
              "       [ 0.04949498,  0.49383678],\n",
              "       [ 0.64331447, -1.57062341],\n",
              "       [-0.20690368,  0.88017891],\n",
              "       [-1.69810582,  0.38728048],\n",
              "       [-2.25556423, -1.02250684],\n",
              "       [ 0.03863055, -1.6567151 ],\n",
              "       [-0.98551074, -1.47183501],\n",
              "       [ 1.64813493,  0.16422776],\n",
              "       [ 0.56729028, -0.2226751 ],\n",
              "       [-0.35343175, -1.61647419],\n",
              "       [-0.29183736, -0.76149221],\n",
              "       [ 0.85792392,  1.14110187],\n",
              "       [ 1.46657872,  0.85255194],\n",
              "       [-0.59865394, -1.11589699],\n",
              "       [ 0.76666318,  0.35629282],\n",
              "       [-1.76853845,  0.35548179],\n",
              "       [ 0.81451982,  0.05892559],\n",
              "       [-0.18505367, -0.80764849],\n",
              "       [-1.4465347 ,  0.80029795],\n",
              "       [-0.30911444, -0.23346666],\n",
              "       [ 1.73272119,  0.68450111],\n",
              "       [ 0.370825  ,  0.14206181],\n",
              "       [ 1.51999486,  1.71958931],\n",
              "       [ 0.92950511,  0.58222459],\n",
              "       [-2.09460307,  0.12372191],\n",
              "       [-0.13010695,  0.09395323],\n",
              "       [ 0.94304609, -2.73967717],\n",
              "       [-0.56931205,  0.26990435],\n",
              "       [-0.46684555, -1.41690611],\n",
              "       [ 0.86896349,  0.27687191],\n",
              "       [-0.97110457,  0.3148172 ],\n",
              "       [ 0.82158571,  0.00529265],\n",
              "       [ 0.8005648 ,  0.07826018],\n",
              "       [-0.39522898, -1.15942052],\n",
              "       [-0.08593077,  0.19429294],\n",
              "       [ 0.87583276, -0.11510747],\n",
              "       [ 0.45741561, -0.96461201],\n",
              "       [-0.78262916, -0.1103893 ],\n",
              "       [-1.05462846,  0.82024784],\n",
              "       [ 0.46313033,  0.27909576],\n",
              "       [ 0.33890413,  2.02104356],\n",
              "       [-0.46886419, -2.20144129],\n",
              "       [ 0.1993002 , -0.05060354],\n",
              "       [-0.51751904, -0.97882986],\n",
              "       [-0.43918952,  0.18133843],\n",
              "       [-0.5028167 ,  2.41245368],\n",
              "       [-0.96050438, -0.79311736],\n",
              "       [-2.28862004,  0.25148442],\n",
              "       [-2.01640663, -0.53945463],\n",
              "       [-0.27567053, -0.70972797],\n",
              "       [ 1.73887268,  0.99439439],\n",
              "       [ 1.31913688, -0.88241882],\n",
              "       [ 1.12859406,  0.49600095],\n",
              "       [ 0.77140595,  1.02943883],\n",
              "       [-0.90876325, -0.42431762],\n",
              "       [ 0.86259601, -2.65561909],\n",
              "       [ 1.51332808,  0.55313206],\n",
              "       [-0.04570396,  0.22050766],\n",
              "       [-1.02993528, -0.34994336],\n",
              "       [ 1.10028434,  1.29802197],\n",
              "       [ 2.69622405, -0.07392467],\n",
              "       [-0.65855297, -0.51423397],\n",
              "       [-1.01804188, -0.07785476],\n",
              "       [ 0.38273243, -0.03424228],\n",
              "       [ 1.09634685, -0.2342158 ],\n",
              "       [-0.34745065, -0.58126848],\n",
              "       [-1.63263453, -1.56776772],\n",
              "       [-1.17915793,  1.30142807],\n",
              "       [ 0.89526027,  1.37496407],\n",
              "       [-1.33221165, -1.96862469],\n",
              "       [-0.66005632,  0.17581895],\n",
              "       [ 0.49869027,  1.04797216],\n",
              "       [ 0.28427967,  1.74266878],\n",
              "       [-0.22260568, -0.91307922],\n",
              "       [-1.68121822, -0.88897136],\n",
              "       [ 0.24211796, -0.88872026],\n",
              "       [ 0.93674246,  1.41232771],\n",
              "       [-2.36958691,  0.8640523 ],\n",
              "       [-2.23960406,  0.40149906],\n",
              "       [ 1.22487056,  0.06485611],\n",
              "       [-1.27968917, -0.5854312 ],\n",
              "       [-0.26164545, -0.18224478],\n",
              "       [-0.20289684, -0.10988278],\n",
              "       [ 0.21348005, -1.20857365],\n",
              "       [-0.24201983,  1.51826117],\n",
              "       [-0.38464542, -0.44383609],\n",
              "       [ 1.0781973 , -2.55918467],\n",
              "       [ 1.1813786 , -0.63190376],\n",
              "       [ 0.16392857,  0.09632136],\n",
              "       [ 0.94246812, -0.26759475],\n",
              "       [-0.67802578,  1.29784579],\n",
              "       [-2.36417382,  0.02033418],\n",
              "       [-1.34792542, -0.76157339],\n",
              "       [ 2.01125668, -0.04459543],\n",
              "       [ 0.1950697 , -1.78156286],\n",
              "       [-0.72904466,  0.1965574 ],\n",
              "       [ 0.35475769,  0.61688655],\n",
              "       [ 0.0086279 ,  0.52700421],\n",
              "       [ 0.45378191, -1.82974041],\n",
              "       [ 0.03700572,  0.76790241],\n",
              "       [ 0.58987982, -0.36385881],\n",
              "       [-0.80562651, -1.11831192],\n",
              "       [-0.13105401,  1.13307988],\n",
              "       [-1.9518041 , -0.65989173],\n",
              "       [-1.13980246,  0.78495752],\n",
              "       [-0.55430963, -0.47063766],\n",
              "       [-0.21694957,  0.44539325],\n",
              "       [-0.392389  , -3.04614305],\n",
              "       [ 0.54331189,  0.43904296],\n",
              "       [-0.21954103, -1.08403662],\n",
              "       [ 0.35178011,  0.37923553],\n",
              "       [-0.47003288, -0.21673147],\n",
              "       [-0.9301565 , -0.17858909]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCmI86Tno3AS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f00223-7d68-4cd4-a766-91ff3184b77d"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sBxgryoo3AT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a0507ca-14ef-4f06-cd0e-7f6be3d6b521"
      },
      "source": [
        "2**2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcX01ZXoo3AT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52aec84-945c-400b-8e30-2fbdfb0ddd4c"
      },
      "source": [
        "4**4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv66yqlDo3AU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib9bpc-ro3AV"
      },
      "source": [
        "### Simple Perceptron\n",
        "Construct a simple perceptron using Keras. \n",
        "\n",
        "Make sure to include the following in your model:\n",
        "- Add `1 dense layer` with a `single neuron` \n",
        "- Use a `sigmoid activation function`\n",
        "- Set `epochs` to 10 \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data.\n",
        "\n",
        "Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "67e9f7297eb22a79437494d713d74b71",
          "grade": false,
          "grade_id": "cell-427690628f9c900b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "c2_dszbfo3AV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5e94b0-235b-464f-d711-69985e25638a"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "#define\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(1, input_dim=2, activation='sigmoid'))\n",
        "#compile\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model1.fit(X, y, epochs=10, batch_size=32, verbose=0)\n",
        "h1 = model1.evaluate(X, y, verbose=0)\n",
        "print(\"Accuracy\", h1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy [0.8798381686210632, 0.49666666984558105]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15Dm0gSI_cOc"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "36f7f830036d0443ca8e8ba0f17b2a4e",
          "grade": true,
          "grade_id": "cell-bf2ae566afacde8c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "aujLFqQGo3AV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ff8fbbb7-7ce7-418c-8edd-aeba5fea218d"
      },
      "source": [
        "# Visible test\n",
        "assert len(model1.get_config()[\"layers\"]) == 2\n",
        "assert len(h1.epochs) <=10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-38ea234183a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visible test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"layers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'epochs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6ozVPOpLAUwb",
        "outputId": "0d9be137-806d-439c-f67b-3272659cfc33"
      },
      "source": [
        "assert len(h2.epochs) <=10\n",
        "#Just can't win, two tries, two errors - \n",
        "#I don't understand why KT wouldn't have epochs but I need to move on. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-0b0e3b411e66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#Just can't win, two tries, two errors -\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#I don't understand why KT wouldn't have epochs but I need to move on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'epochs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-XydQRFo3AW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45571b8-462f-404f-ba00-ef04616c6df2"
      },
      "source": [
        "model1.get_config()[\"layers\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'class_name': 'InputLayer',\n",
              "  'config': {'batch_input_shape': (None, 2),\n",
              "   'dtype': 'float32',\n",
              "   'name': 'dense_8_input',\n",
              "   'ragged': False,\n",
              "   'sparse': False}},\n",
              " {'class_name': 'Dense',\n",
              "  'config': {'activation': 'sigmoid',\n",
              "   'activity_regularizer': None,\n",
              "   'batch_input_shape': (None, 2),\n",
              "   'bias_constraint': None,\n",
              "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "   'bias_regularizer': None,\n",
              "   'dtype': 'float32',\n",
              "   'kernel_constraint': None,\n",
              "   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "    'config': {'seed': None}},\n",
              "   'kernel_regularizer': None,\n",
              "   'name': 'dense_8',\n",
              "   'trainable': True,\n",
              "   'units': 1,\n",
              "   'use_bias': True}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "95d3ee2935a0de64f2a5a22460520e69",
          "grade": true,
          "grade_id": "cell-a957e14380b2f508",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "XieSAdGFo3AW"
      },
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGa9jEI-o3AW"
      },
      "source": [
        "### Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron model (also known as a neural network). \n",
        "\n",
        "Your neural network `must` have: \n",
        "- `2` Hidden Layers\n",
        "- Select any number between `5-32` for the number of neurons in each hidden layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the `Callback function` below into your model\n",
        "- Set epochs to `100`\n",
        "- Your model should be called `model2` \n",
        "- Save the results of your fit statement to a variable called `h2`. \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ANZJPd0o3AW"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        # if model reaches 99% accuracy, training is terminated \n",
        "        acc_threshold = 0.99\n",
        "        if(logs.get('accuracy') > acc_threshold):   \n",
        "            self.model.stop_training = True\n",
        "            self.model.callback_used = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "314337f29c8cd7f38224a31687a86b12",
          "grade": false,
          "grade_id": "cell-77523c4c64743f16",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "THUqz0hYo3AW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39eb396-a576-42e4-d120-fe758ea5793b"
      },
      "source": [
        "# build and fit model\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(12, input_dim=2, activation='relu'))\n",
        "model2.add(Dense(8, activation='relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit the keras model on the dataset\n",
        "model2.fit(X, y, epochs=100, batch_size=10)\n",
        "# evaluate the keras model\n",
        "_, accuracy = model2.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7888 - accuracy: 0.3314\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.7353 - accuracy: 0.4100\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 992us/step - loss: 0.6941 - accuracy: 0.5242\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.4917\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6680 - accuracy: 0.5857\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6057\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6431\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6305 - accuracy: 0.6651\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.6407\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5960 - accuracy: 0.7002\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.7307\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5550 - accuracy: 0.7401\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5505 - accuracy: 0.7211\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5287 - accuracy: 0.7771\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.7980\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8181\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.8218\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.8562\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.8470\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.4249 - accuracy: 0.8762\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.9066\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.3659 - accuracy: 0.9090\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8995\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.9083\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.9048\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8875\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.9073\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.9222\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2814 - accuracy: 0.9431\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.3043 - accuracy: 0.9212\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.3111 - accuracy: 0.9388\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.9405\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.9415\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.9464\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.9551\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2666 - accuracy: 0.9502\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2657 - accuracy: 0.9286\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.9548\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.9590\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2328 - accuracy: 0.9494\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2335 - accuracy: 0.9476\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2309 - accuracy: 0.9544\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.9668\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2039 - accuracy: 0.9805\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.9839\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2018 - accuracy: 0.9727\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.9749\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2107 - accuracy: 0.9569\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9813\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9709\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.9630\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.9497\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.9760\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.9840\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.9880\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.9723\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.9824\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.9652\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9878\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9871\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9802\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.9772\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9845\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1640 - accuracy: 0.9754\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.9676\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9812\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9702\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9823\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.9711\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9909\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9825\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9775\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9654\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9799\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 997us/step - loss: 0.1406 - accuracy: 0.9863\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9901\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9823\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9883\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1377 - accuracy: 0.9882\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9887\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9911\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9896\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.9919\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9908\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.9860\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9941\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9888\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9895\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.9951\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.9940\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9892\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0987 - accuracy: 0.9957\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9922\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1017 - accuracy: 0.9845\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.9916\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9884\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9925\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9854\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9853\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9954\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9900\n",
            "Accuracy: 99.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDhoM619KkEK",
        "outputId": "108f71a5-0971-4a76-d9e2-ae6df987b16f"
      },
      "source": [
        "h2 = model2.fit(X, y, epochs=100, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0973 - accuracy: 0.9933\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9933\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9867\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9933\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9933\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0915 - accuracy: 0.9933\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9933\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9867\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9933\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9933\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0862 - accuracy: 0.9933\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9933\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0844 - accuracy: 0.9933\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9933\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9933\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0817 - accuracy: 0.9933\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0811 - accuracy: 0.9933\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0806 - accuracy: 0.9933\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9933\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9967\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9933\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9967\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9967\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9933\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9967\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9967\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.9967\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9967\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0719 - accuracy: 0.9967\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9967\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9967\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9967\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0690 - accuracy: 0.9967\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9967\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.9967\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9967\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9967\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9967\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9967\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9967\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0628 - accuracy: 0.9967\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9967\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0618 - accuracy: 0.9967\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9967\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9967\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9967\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0588 - accuracy: 0.9967\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9967\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0576 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0569 - accuracy: 0.9967\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9967\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 990us/step - loss: 0.0566 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9967\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0549 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9967\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0538 - accuracy: 0.9967\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9967\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0527 - accuracy: 0.9967\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9967\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9967\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9967\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.9967\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9967\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9967\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9967\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9967\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0471 - accuracy: 0.9967\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0449 - accuracy: 0.9967\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9967\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9967\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9967\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9967\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9967\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0393 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0383 - accuracy: 0.9967\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0354 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4a5f575f46f151f97f1cebc19a484bae",
          "grade": true,
          "grade_id": "cell-770612ca24334d8a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "STe7X-8Uo3AX"
      },
      "source": [
        "# Visible test\n",
        "assert len(model2.get_config()[\"layers\"]) == 4, \"You should have 4 layers: Input, hidden 1, hidden 2, output.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][1][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 1, but don't.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][2][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 2, but don't.\"\n",
        "assert h2.params[\"epochs\"] == 100, \"You didn't set epochs to 100.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2s6bT2zMOzQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3ca73d4d3d17897a570e19a8a97c050f",
          "grade": true,
          "grade_id": "cell-49b1bf7cce22b5b9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wCw7jeLMo3AX"
      },
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XiqmgPao3AX"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. \n",
        "\n",
        "Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "You can install this package using the following statement in the terminal\n",
        "\n",
        "```python\n",
        "pip install mlxtend\n",
        "```\n",
        "\n",
        "Or you can install this package using the following statement in your notebook\n",
        "\n",
        "```python\n",
        "!pip install mlxtend\n",
        "```\n",
        "\n",
        "If you choose to install this package from within your notebook, be sure to delete the install statement afterwards so that CodeGrade doesn't try to install it and potentially crash. \n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU7RVv7KRWhO",
        "outputId": "8e4bc3d7-8e88-4361-84ba-557581e80b12"
      },
      "source": [
        "!pip install mlxtend\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (54.2.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwc4Mfgxo3AX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d86b03d-aa88-4448-dd30-6e751782232f"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300, 2), (300,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTvL_VcBo3AX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "outputId": "0e9e1e5d-f7f0-406e-e0ce-fbfe7c1ddc75"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-8290a86bf94c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'history'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAFlCAYAAAC0tBC9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hUZfr3v8+U1EmfhIQQmgQWQ0tQLBgRERUMxYYgiMgKLAq7Aiu7Lq7o67q6rqL+CKKCIh0URTE0YakLCkgNyBqVFiIpk0zKpE457x/DTGYm08+ZnCn357pyrTk585x7suQ793O3h3EcB4IgCII/ErENIAiCCBZIUAmCIASCBJUgCEIgSFAJgiAEggSVIAhCIEhQCYIgBEImylMPL6ZaLQe899Ux1PadhNQuPcQ2hSAIO0y7sztz9DPyUP2MP4wcgKKdn4ptBkEQXkCC6meEh8kxpFsErhYVim0KQRAeQoLqh0wZ3g8X9qwR2wyCIDyEBNUPkcmkeCArCRdOfye2KQRBeIA4SSk7GMBQL02EXhYBwGHMV0Q4SHVNiNZXQQLf59TGDemNrUu+RLd+t4Ixf/x9EARhi98Iar00EXJFPBRMD3/UD44DmrkI1GuAGH2lz58nkUgw4ZZ07DmyG71uHe7z5xEEwR+/2fLrZREI91MxBQDGgHCmv+5Btw8jbu6BypM7YTAY2u2ZBEF4j98IKsD8VkxNGO1rPyMZY5g6tDvO7d/Sbs8kCMJ7/EhQ/YMdB4+j18iZ6HHfdLyxbJPY5iC3Txc0FB2EXqcT2xSCIFxAgmqBXq/Hs//4ENs/XIgfv1mC9dsO4MdfrohtFp69txfO7NogthkEQbjAb5JSnjBo0gKoahrbXFfGReLomte8Xvdo4c/o0TkN3TNSAQDjR+Ti6z1HcGOPzl6vKQTZmenAf/ZC2/wo5OHhotpCEIRjAlJQVTWNyJrxTpvr5z6cw2vdkrJKZKQqzd93SlXiyJmfeK0pFM89kIW3tq/GzWOfFtsUgiAcQFv+AKFnRgqi1D+hqUEjtikEQTiAt6AyxiIYY0cZY6cZY+cYY68IYZgYpHdIQnGpyvz91VIV0lOSRLTImj+P6Y9TBSvENoMgCAcI4aE2A7ib47j+AAYAuJ8xdqsA67Y7N/fJxM+Xf8PFq6VoadFiw/aDGD30FrHNMtMpJQHKlqvQ1KjFNoUgCDvwFlTOiGkfKr/+FZDzTmUyKfIXzMB9015G71HPYtx9dyArU9yElC3Pj83B6W+Wi20GQRB2ECQpxRiTAjgOoAeAJRzHHRFiXUco4yLtJqCUcZG81x455CaMHHIT73V8hTJegW5yNdQVpUhIThXbHIIgLGAcJ5wzyRiLB7AZwGyO487a/Gw6gOkA8OH8xwZOHzPY6rXV4Z0QH+X/RQfVDTrEN18V1Yba+kbMXv8/3DHlRVHtIIhQpN0m9nMcVw1gL4D77fzsI47jbuI47iZbMSU8IzY6En3iW1BRcklsUwiCsECILH/ydc8UjLFIAMMB/I/vuoRzZo3Kxv+2U8afIPwJITzUNAB7GWNnABwDsIvjuAIB1iWcEBkehlvSpSj59bzYphAEcR0hsvxnOI7L5jiuH8dxfTiO+39CGEa4ZvqIAbiwe7XYZhAEcR3qlApg5DIp7ukVg8vnjottCkEQIEG1YuqC95ByxxPoM3qW2Ka4zaS7++DygY0QslqDIAjvIEG1YMqDw7Djo5fFNsMjJBIJHszugF+OHxDbFIIIeQJaUFXqWjw86/+hsrpWkPXuvKkPEuMUgqzVnjw4uBfKjn1DXipBiExAC+qqL3dCXfILVn6xU2xTRIUxhicGd8b5Q9vENoUgQpqAFVSVuhYFu/Zi6UMdULBrr2BeaqByT84NqCncA4NeL7YpBBGyBKygrvpyJ/JuYOjVIQJ5N7CQ91IBYMY9mSjc86XYZhBEyBKQgmryTicPjAUATB4YS14qgFt6Z6Dl4vfQaVvENoUgQpKAFFSTd6pUGIepKBUyQbzUCX/+N26bMB8/XSpBp6FP4eMvvhXC3HbljyNuxOkd68Q2gyBCEv8f72SHfUdP47drzVhXeM3qekfVacz9/aNer7v+ref5miY6fbqlQr5rH5qbGhEewX+cIUEQ7iPo+D63Oby4zUNpfJ9wXLpWidcOaDDo4WfENoUggo52G99H+Add05IQp7mEhrrQjikTRHtDghqk/HlsNk4XfCy2GQQRUviRoHLw90Yfo31+buR1UpNi0RHlqK1Sub6ZIAhB8BtBleqa0MxJ/VZUOQ5o5qSQ6prENsVt5o3JQWHBMrHNIIiQwW+yQNH6KtRrgCZZBACHMV8R4SDV1SFaXyW2IW6TEBuFzKh6VJaWICk1XWxzCCLo8RtBlYBDjL4SoM5JQXluTA5mrl6O3KkLxTaFIIIev9nyE74hOjIcA1M4lF7+RWxT2lBXXYVlC34PTY1abFMIQhBIUEOAP4wcgKKdn4ptRhuObd8IWVkhjm7bILYpBCEIJKghQHiYHEO6ReBqUaHYppipq67CTwc24+0H0/HTgc3kpRJBAQlqiDBleD9c2LNGbDPMHNu+EaMygR4pkRiVCfJSiaCABDVEkMmkeCArCRdOfye2KWbvdEJOHABgQk4cealEUECCGkI8dteNuHr4S9GPSjF5p0nRcgDG/yUvlQgG/KZsivA9jDGMH5SOvUd2o9etw0Wz4+eTh3CyvAkbz1gPmVGUHsLdE2aKZBVB8IcENcQYOagHNuXvhGHQMEgk4mxQZrzJL5ZbV12FDf9+HhPmvwVFXIJAVhEEf0hQQwzGGKYO7Y7P929B36FjxTbHKyzLrQLFo3191gRoNHVtrisUMXghf70IFhG+gAQ1BMnt0wUr9++BPjcPUllg/RMwJbSWPJiOZws2Y9DI8QHhpWo0dej+9OI21y8sny2CNYSvoKRUiPLsvb1wZlfgJYGo3IrwZ0hQQ5TszHSg5BS0zc1im+I2VG5F+DskqCHMcw9k4eS2VWKb4TZUbkX4O4EVQCMEpWdGChQ796OpQYOIKIXY5riEyq0If4cENcSZN7ofFhaswK3j/D85wrfcSkwUihi7CSiFIkYEawhfQYIa4nRKSUByy1loatQBkS0PVKg0KjSgGKqIqKo1ePivH6Cypl5UO+aNGYDT3ywX1QaCCAbIQxWRVVsPQ11ajJUFhzB34r2i2ZGcEINucjXUFaVISE4VzY72hortCaHhLaiMsQwAqwB0gPFI0I84jnuP77rBjqpag4L9x7D0ISVmFhzDk3mDkRQXLZo9c8bmYPb65bhjyoui2dDeULE9ITRCbPl1AOZxHHcjgFsBPMsYu1GAdYOaVVsPI6+HBL1SwpHXQ4KVBYdEtSc2OhJ94ltQUXJJVDsIIpDhLagcx13jOO7E9f+uA3AeAB2x6QSTdzo5x+iRTs6JRsH+Y6LHUmeNysb5bZ+IagNBBDKCJqUYY10BZAM4Yudn0xljPzDGfvjoa3G9MbExeadKhTHiolTIPPJSfZXMqm9swdkj+/Dz6Tb/9/kEOqSPCDYEE1TGmALAFwCe4ziu1vbnHMd9xHHcTRzH3TR9zGChHhuQ7DtRhHWFzbhpSbn5a11hM/adKHLr9ZbJLCFZtfUw4rga7Fnxutuv4SOKdEgfEWwIkuVnjMlhFNO1HMd9KcSawcyWt2d5/VpfJbNM6374cDIeXFuM80f2ovctQ12+zttRev4wNSrQi+2pSsH/ECLLzwB8DOA8x3GL+JtEOMM6mdUkWMmV5bpTcyKwYd07LgWVjyhaT42qF2W2aaCLDlUp+B9CbPkHA3gCwN2MsVPXv0YKsC5hg6+SWbbrThmoQHNVCQoPbHX6Om9H6dlOjRrXX4GjXy5FWfFFXu+DIMRGiCz/fzmOYxzH9eM4bsD1r21CGEdYwzeZ5cm6UwZE4LtNHzg80I/PKD3bqVGRujqMuUGPLe+/zOt9EITYUKdUALHvRBF+K2/GusJyq+sdy4p4bfsdrSsPr8P5Q9tw4x0PtHmNs1F6rrbullOjDAYD6qtVSIxkUDUdp5kCREBDghpA8Elmebvu1MV7YLjtfkikUqvrfEbpWU6N2rN+KXpe24xZuUrkH1R5HUulBA3hD5CgEk6ZcU8mVu/5Ev2HP2p9XYBReqawwcLHWsMGj2/0LuMfigmaQK9SCEZIUAmn3NI7A5/s2wuddgxk8jBB1+YTNuBDsHizgWRrqECCSrjkj/f/Dot3rMPAUVMEXVeoCfx11VVoVhVD21ADeVScy/uDyZsNlg+HYIEElXBJVrc0yHftQ3NTI8IjIgVbV6gJ/Me2b0Q3RTNqTmyD8o4JgqwZKATTh0MwQAOmQxBvZgHMG9UXp7eu8Og57dGrb4rDvjw0Gtz/dkHbUOOzZxGEK8hDDUG8GWzdNS0JsZqzaKirRVRMrFuv8bYt1RNMcdgblGEYmVqJtR/+AbIYpfnnlKAh2hMS1BCDzyyA58dm428FH+O2CXNc3tsevfqWVQJJ0Uo8m6TFoZoaPPHGaqplJUSBBDXE4DMLIDUpFh1xBrVVKsQmKp3e2x69+t5WCVC5EeErSFBDCJN3+tk4o3BMzonGuM8881LnjcnBnE3LMHjyCw7vEbK+1BneVgkEU/abPhz8CxLUEMLZLAB3vdSE2ChkRtWjsrQESan2D2Y4uHkFhiRWICHCKJ6+qi8VqkogkAmmD4dggAQ1hBBqFsCfRufgmTXLkTt1od2fn9lXgGNV9fjyp5+g02kRHZsAiUTicX2pibrqKmz49/OYMP8tio0Sfg0Jaggh1CwARVQ4BqZwKL38C1K79LD6WV11FeKi5FgyLguPr76KznEydL1nIi/PtD2qBQhCCEhQCa/4w8gBeHr5p0id/g+r66ZEUUK0DDHQ4NVhKZh/wPv4qT9M9g92qNtKOEhQCa8ID5NjSLcIXCk6g4ye/QBYJ6M+P1aOx/uGoWNYA/K6y732LvlUC4SKUPB9n9RtJRwkqITXTBneD099sNYsqCbxA4DdP1ZiwyPRMHAGjO5hwPRvPfcu+VYLhIpQhMr7DARIUAmvkcmkyOuThFOnv0P3/reZy5g+PlSBRzKBynodACBK3ohRmTEee6liTaMSklDxkgkjJKgEL8YNuREF+V+iW79bzWVMH86fhB2lV7DD6iCcJo+z/EJNoxIT8h5DCxJUgheMMYwflI69R3aj163DAQhXHxrIdaYmz1StKkfJpZ/N16VSKVIzuotoGeFLSFAJ3owc1AOf5+9A5qBhkEhogBnQ6pmeyZ+JcGVn8/Vm1RURrbKPu91WFL5wDQkqwRvGGH4/9AZ8vn8L+g4dK7Y5ZpwJRTCJA9/2U3ffL4UvXEOCSphRVWsw4401+OiFJ9zu7TeR26cLVu7fA31uHqQy4z8rsTucnAnFgil5vMRBCEEWStQD7QMgmCFBJcx4MyfVkmfv7YVluzYie8REAMHd4eSutyaNiMJvnz5n/l6rqUKzMgUKRQx5fEEIBbwIANZzUgv2H/Nomr+J7Mx0oOQktM3N5hrStx9Mx08HNvt0ar8/k/X02+g3a6n5K0GZgtc+LSCvMkghD5UAwG9OqiXPPZCFt7avRl2j1uMOJ7FDBEJCY/VCExJUwumcVI7jPIqr9sxIAfv6W/x44hwWPm4URXc7nIIpROCtB1pafAFqVTkWTMmzuu4PyTL6kHANCSrhdE4qAI/jqh3kjeggrUFSdAoA9zqc2nsIir+Kg16vh1yR2Ca26g9xVbEFPRAgQSUczklNLjmP5kaNx+dPnSoqRuG1Jtz+f5chlUrN1511OLXHkSmW8BUHIQTZ3hpqVTkilJ142UaIB+M4rv2fenixCA8lPGXR2m+BkuOYe2ccFh2oAdIHuu2lqqo1eP6rK7h90vMu762rrsKaF8Zj3WNxSIqWo7Jei8c31uCJNzY69FKvXbmA9+c+hlnvfIYOGd08el++hk85lLNyrtc+LRDMRsJ7pt3ZnTn6GWX5CbuY4qqTc4we6eScaKvsv6pag4f/+oHDagBlvAJd5WqoK0pdPsvZEBRHFCx9BemyGmx5/2UP35nvMZVD2X7ZE1kiuCBBJeziKq5qWbPqiDljc3Bu63KXz/r55CFsPNOE3CVXzV8bzzTh55P217525QJUPx3FsrExUP10FGXFF714hwQhPBRDJezi7PypyQ/cbq5ZdRZbjY2ORJ/4FlSUXEJyeleHz/J0CErB0lcwPkuKGLkB47Ok2PL+y5j2+kqP1vAnLEMENZUqHH/jMQAA4wyIT04FIH6yjHAPElTCLlvenuWwFXXR2m/drlmdNSobM1asQPLTrwhil8k7HT8uAga9AeOz5NjwmdFLFTKW2p69/s46pihuGliQoBIOsdeK6qxm1Z6XGhkehlvSJSj59TzSb+jN2yaTdxomNaBznASXq33jpXrSFmorvmpVOc7kz4Q0IgpZT78tmE2E/yOIoDLGPgGQB6Cc47g+QqxJiItlK6rltt5ZbNWRlzp9RDamfrgK6Te8ztuu4p8K8UlzMzYWAtFyQNPCoUELsIhC3mt7i634lhZfgF6vR+mGF60EWKxtezBN1vJ3hPJQPwWQD2CVQOsR7YCz6VKOWlGdxVYdCapcJsU9PWPx87nj6JI1kJfNz3+yG2teGI/VjyjA1MWICgPu/lSDqe994fR17SkqpgHSzdf79sWGhrC0H4IIKsdxBxhjXYVYi2g/HE2Xcrat3/L2LK+e9cSwPnhyyUbegmoqsYrU1SE8AkhRyDChj8zllp9EhWgP2i2GyhibDmA6AHw4/zFMHzO4vR5N2MHRlh5wXjLlSWG/pfcrkUjwUE4HfH/8AHoMvNNru38+eQjHSxuwfJ8KyigJpBJAbwDKG49DU6MOyKEq/toG6w2hHl5oN0HlOO4jAB8BoE4pP8Deln7yA7djxhtr0NDYjIoqz7b19ta39X7H3t4LX+VvwQ05uWDMYbOJU2a8uQZ71i9Fz2ubMStXab6ef1AlaLuqPZGrqVSBM+jaDC6pqVTxepZYQlNTqWrzXgB+4hfqOwHK8ocgjrb09U0tUJcWI2/4EK9G99mub+v9MsYw+Y4uKPjvVtyY2/YP2RWm8X4tDRqcVPv2NFR7guKoLfTE648GpIdp4AwhLX6+gARVAPgcHSIG9rb0I7oDn+w4jK+eSPZoEIqz9e3VqQ7L7o51+XthuH0EJBaDU9zBNN7vhmFP+dV4v/jkVL9IPjnCUUiBcQYRrAluhCqbWg/gLgBKxthVAAs5jvtYiLUDAb5Hh7Q3tpl6nd6AqxV1SI3lP2DanTrV6cN6YPWeL9F/+KNur8t3vF8wxSkBz2KVjrbv9rb7BD+EyvJPEGKdQMRZcsdfsc3Uv/pxAb7avgdj+/IfMO1OQuuW3hn4ZN9e6LRjIJOHuWUz3/F+voxTVleUCh6LdEWoxyr9Fdry80Soo0N8hatwhKpagy92fYf8kZF4aW89nrlDz2vAtLt1qrPv7438HeswcNQUp+vVVVdh9T//BNT8hoUTEgG4fwJAe8ExCYnbdYJtJ+ApJKg88LQNUwxchSOWfrEPQzq2IDEiHP07AP3fuYK6hhZkJMcg/ep5aJs8GzDtbp1qn26pkO/ah+amRoRHRDq879j2jai/eBJj+yqQFN0BgOMTAHxdsuNILCQsMIe2+UL8QqE0yhkkqDwQol7Tl7gKR5i80w/ulSExToEF96fg8/9dQY9ECTp3SUNu/0yg5LjPvO95o/rita0rMOjhZ+z+3BQ3TYuVYu0P1fjqlyuQSFrFyzar7+ttcLDFIkNd/HwBCSoPvGnDbE9chSOWfrEPwzK0GNAxEper66HThiGM02HZ6CiM2/QrysorsWVSPADfeN9d05IQpzmLhrpaRMXEtvm5KW46KzcL+QdVKEp70K+y+wRhCwkqD7xtw2wP3AlHfLH3BBpqddh/WYPaJg7qpjpMy5bhRqUED/aS4qxKA6XCWDzvK+973pgBWFDwMW6bMMfqusk7XfhYHADfxU29DRNYvs40XQpAu02YCvVYpb9CghqkuApHqKo1SIySYveUrlAqZPj+YgPGry7G7NuiEBEmxcO99fhsUwP6vXsNMqkElTX1SIqLRicvvG9nibE0ZRw6ohC1VSrEJrZ2Pjk7FkVIL9UyTHBu+TzomxoAAGrVr+atvD1xtXydaboUAKsJU74UN0+266HeDtqekKC6SaAV77sKR9gK7r/2VmJiPzmUEcb7bu0cgScH6FGoS0Vu/0wU7NqPvOGDvfJOXSXG5o3JwZxNyzB48gvmaz+fPIST5b7thrJF39SAjlPeBQA0q64gvWsmANcxWNN0KcCzCVPtJXRUYtV+kKC6SaAV77sKR9gK7oVrDfjuEvDJyRqrxI9MfgU11dVe19m6U6ebEBuFzKh6VJaWICk1HYDnx6IAnvXf+4N3RkIXfJCg2sHWGw2E4n1PPWh347+mo6S9zfS7SoyZ7H5nzmN48evlyJ260O21bXG3//7c8nlQXzJu6SuvXUXV68YznDiDHsUr/gQAYBIZ0p/N99oWIjQhQbWDrTfq78X7gG88aL51tu683mT3pt3HkJOcgNLLvyC1Sw9edrtKGOmbGpA6/h9I75qJ6nefRsepRuFsKb+IsBTjuVS/fSJMwtHZtp4IPkhQbbD1RvNyB/h98b6vPGi+dbbuJMYs7V7zz1n4y2efInX6P3jZbbmVLrn0M8KVnQEAv336XJt7GWPgdC3Xv+PM/+1qvKC7WXba1ocWJKg22Hqjf8n/3K+L9wHftb96U2drGXpwNzFmsnvDziMY0i0ZxUWF6NSzL2/73UEqlUEeFg4A0ILBUFsGADA01jrN1osdfzXhTmKLSqzaDxJUC+xtUT/Mv4SLVyOxrrDZ6l5/Kd73ZfurN3W2lqEHZ693ZPf6N2bjz+vWoFPPf3n0XEfbfAOTotOT7tWFSmUyc2a/Pc6DEkLo3PGA/UX8QwESVAvsbVFn3J4IpA/0C/G0hz+1v3oSenBk99rt3yOvTzpOnf4O3fvf5vazNZo6RN03B3q9Hsk6HZjEuG7ZxgW4unIekh/4E7SaKlxYPhtaTRWkHs5i9QUv5K+362FqNHV4fdYEEsIAhATVAn9vJbWHP9nsSejBZPea02XmpgGJhKFjWRG+fnw4CvK/RLd+t3p0VIper0e4sjO0Lc1gMuNYQKkiERJOj/SumWav8/VZE6DZ+Q4uANDVqXA5fzIA45CT5iRjc0F7bYcpxhpckKBa4M+tpID90qhP/j7FLxoOPA09mH7Xi9Z+a7dpYMIt6dhzZDd63TocQOvxJxPmv+Wy9ZQB5uQSp9dB21SHC8tnm0WyPT0/il+GFiSoAYS90ihnR0G3p9B6E3pwFiIYcXMPfJ6/E4ZBwyCRSMzHnzhqPTXoddDsXgLZ6AWQRbUOWpHJ5FDwiIfy7WaibXtoQYLqQ4QUNXviw3Gc06Og27Ozy5PQg+n3MiCzk8MQAWMMT93VHZv2b0HX7DvtHn9i6bUaGqrRJaoZ5Wd3IGrQOACArqUZOp0WalWVVaeUJ11S9rbkpcUXULz2Bb/ovnLXA6Z+/vaBBNWHCClqlvHJuzIaMHzWO3jwrgF2Bak9OrtsPyw8CZes2noYVdeuYN2vV3BwRioA+yGCO/t2waoDe3Ck5Krd409MXuvBLz5BLKfBn3IkmLtjFarO7INEFgadTgtJhAIGAOH3/NH8/OINL5qTPt4IjV6vh1yR2EZoxYh78vlgAFptJsEVBhJUHyGkqKmqNfjyP0eQIKnHkwMVYAYtWGMt1mw9hEPPpAGwFqT26Ozy9sPC9Ht5dVgUZm1Rm5NOSoUMd2UAw2e9g135c8y/q4m3dcZTr6/GKzOMxfmmMX43Dr7P7LU+vnoDJt+WivOqcmQmSfBzrQpyZWeoVVUwAJBGxpqL+wFArkg0i4cQSSHTlCqtxnNP2F9irJQcEwYSVB8hpKit2noYyfIm1NRr8f5/K7H3l3q8c184pn3TZCVIeT0kWPL5Xuw7etqnnV18PixMv5cOkc0Y2lWCmxdfRWKM8QiUqrpGJMp1Vr+rk+cvoGt0M6LDjGVOpjF+3yx9BaMygYRoGWKgwZ3pUXj1RwOWjY3FgxvqMfXVxfi/v89G+D1/tBJTV5hG8alV5VgwJQ9qVTmu/PIjAAapzPjnotfp0FJXhXPL55lbWTtOeddqQhVgFCNXnh95f8EFCaoPELrYfueR8/j5t0YsHhGOZ7dW4/4eMsRHMNx3g9RKkABAZziOyf3DfFKX6k7s09XrTb8XpSIOCxJ0OP1ZHT7/93PgOA7j5r+HpXlRViK970QRVE0S3PxWEeJjFQAAg8GAuprjmDCnNz4/Vo7H+4Zh97lKPJApxY0pckzoI8OW91/26j2aSq9MW/oz+TPBJHLI4ju0dlS1NEOqSDDPTnVEVfk1VJZfQ4dxr1pdZwA0+95vcz9tuwMfElQfIHSx/X239MZ9nRpwb78YPHzxCuIVUeiXmYKX0nQ4e12QTEI9el4+1hWqfFKX6m7s09nrHf1eANgVaVNsds7y/eg+7iVERCmwZ/1S9Ly2GUnRchz+tRYl6hbUNuqw8sEo/HitAcO7MqzafBhVhjik6HRoLL8CJpEgQtnJ4/csjYhC2cYXIYmMgUxmHHat02khjYwFtI1OX8sBkMUozQNXTLSUX7R7P227Ax8SVB8gZLG9pVdXWaPB1OwwzN7e9rhn07ruJoc8rUBwFvt098Ni34kiXLnWiH/tUSEtMRoyqXHuatL101WdefTzRvfDwoIVuHXcbJvh0zHQ6IBHbtQiOT4KLVo9OnTrjEdvrcLyE81QFbwNJpVBr1EjLMZ4DLU0IgpAiz0TAQBNqqtoqasyt6+aME2rMoUFTNP5tZoqNKuumLuvzJP/OUCvqcK1lcahLCwsCqkT/unyd+0L/CVWG+yQoPoAIYvtLb26n9VNYAzo3wFWW31vhNrTpJKz2Ke7Nmx5e5ZFIf8d5vtNM1edefSdUhKgbCmEpkbdZvj0h/MnYUfpFez4GqiurIZM8RsAQKHsiMS7ZprFTxFh+ufeYhYSW6FRq8rBcYA8MR0dJ74OAGgsvwJZfAdUrPsLgNYJ/abOqwVT8qxip6aYakPpr4BEhrDrMXEoHEIAACAASURBVFyTsIpBoCTHAh0SVB8gZLlUW29XBkCGPjcove7s8jSp5Cz2KcT0fnc9+j+PycbzXy/H4EnPW933+N/+z1yP+vqfnkAni22z5TlR9rAVmgVT8qBp0pnF1B1sxcjksYJzewnRoRitMJCgCozQNaC+aIf1tALB05iwo3CCo+e6+x6TE2LQTa6GuqIUCcnGGG5ddRWWzBmHFEk1jm7b0OY1zjLw9lAoYqBW/WoUxOtwBi20VSXm4SqW9wL2RTm9ayau/HIejEnQcn0t0/ZfV6dCl+493XrPRGBBgiowfMql2qNd1JsKBE9jwpYe+uQHbseMN9bg9WcecvhcjuPcft9zxuZg9vrluGPKiwCA/365AqguxquPpmL+gc0w6CVOX++KF/LXt9nCm9B52MLKAHB6rfl7jjPAUK9GmExm1yOkbXfgQ4IqIHzLpdqjXdSbCgRPvGRbD72+qQXq0mKng7oBWAnwU6+uBAcOK196qs3vLTY6En3iW1BRcgkR0bE4+e0GPJ0Tjo5hDRjZVYolB0rxy4czIZEan2ObMGpPMnr0tvpel5LmVJCF3HZTCZY4kKAKiLtiZc8Tba+DAH097s/SQx/RvQGf7DiMr55IxuhP7A/qNmX4LQVY9dtlVDdxDkV+1qhszFixAhpJLGKgwdScWBg4A0Z2bsD6MD36330vRjw1FwAcepuW2IpPdUUpjr/xGCRMgrjr4/wA+56iPeGqrijFyX9NsHqto9f7CirBEgcSVAFxV6wcTY1qj4MAfTmi0NZDH3kDsPaHZiijHQ/qtjxVdUT3Bny87RDeuUeG1w62YPN/jtj9YIkMD0NWog7/t3YNZueEQRktgU4PVGka8VR2OD7euR65Dz3lcsyfCWfi42qLbznY2kQHwFhVQN5gyEGCKiDuiJWzqVH+fBCgO1h66FqdATJ9Eyb2lWPlsWpMvimuzXuyFeAR3YGV3zciIy4aD/1Ojv9cbmzT22+isUaFJk0dNp4Nw2fnamDQG6Bp1oNJJFCEG8wDVOqqKnD8jcfa2CqTuB5cXVOpajNRCmi7bdbr9VDtXApDS2s1AccBxZd+xeuzJgAAbb9DBBLUdsaeJwpAsM6q9p6Daomlh15b3wToWhAbwdAxth5z70pq855sBZhpGzChjxybzrZgxqBI5B+pRUx4I97/Yi/+PtVa2L7afwpgQGmjFDGxcajXqKCMkqNjfDjeGd8Dj280jvmLSUz2eutr4Axuv9bQ0gBl3p/BcYbrF4wea/Gml8E4A3Je+NytdSj2GdiQoLYjjpJWYREKqNTCxDWFSmy5EmZ7P7f00EfPy8fV0gpU1NTDIA/HTUvK27wnSwGu0TTCoG1CfDhDQiTD0wMNGNVThhYD8MW33+GZh4daebaJUVKsn90Fw5ZXIuuuB9Gveidm5bbGLEdlwm4ZlS/hOIO5iN+gbQFjxslWWk2V22tQ7DOwEURQGWP3A3gPgBTAco7j3hBi3UDCHc/QUdIK6b0FiZcKmdhyJcyufm7dFTXY4T0mu/tOeBlRUgYdB1ysNmDgh3WIDQcyYiW4p7Permfbu0ME7s+UY/uOz3E+Kux6K2oritJDXr33YIBKsMSBt6AyxqQAlgAYDuAqgGOMsS0cx/3Id+1Awh3PsD0z7HwSW66E2R3h9kTc39+0D9EyPb6enIysjAScvazG6FUV2DoxBrERDJXacMzeZT/e/K8RCdixuAzT392GmPjENmvbi4Ha4kh8mGn7bgfT1rymUgXduhcAzlhz2mLREAAALXVV5vOt2hMKD4iDEB7qIAC/cBx3AQAYYxsAjAEQMoLqrni0Z4adT2LLlTC7I9zuiruqWoP1Ow/j6YFhkOmb0NSiA3QNmNhPjoKfWjD7tkjUVDVhRPdIu/Hm5Bg5xvQKx5b3X8HEv73n0fs0YRIf24MAnYmx5da8tPgCfvvin2BMAnliJ2NFP4z/I1UkQFen8souIvAQQlDTARRbfH8VwC0CrBswtFfJkzs28E1suRJmd4Tb9p5bU5rw+Ppv8V7BaasCe2VMOMbfkYlwtGDTjxw+OaFFs6EBOp0OAGDggHXndKht4gCZFr+rKAIAu15++cXvYdDrIbEp4Lf1Pg16HbTqa4jv1LY21fYgQGfbZsvEUWpGd1Qq4lC28e+QxSQBFkdfS8KiwMACcvvt7kmznpxIG+y0W1KKMTYdwHQA+HD+Y5g+ZnB7PdqnCD1M2luECidYCvP5yxXQ6Q3oG9uEPpPfRGRMHBrrajC+ZwuUCuMfjj3hthX3mDDg0Zs7YJc0Fxm5D5ufdeaD51Cw/xh2z+gMpUIGlUaHwfnFiIyNM4/2A4DYcKBjivNhMEfPF2PVni/Rf/ijVtdtt7571i/F5f+sQJchw6yu11VXtTkI0Nm22dZ7zXr6bfzwxngkjXzOPNnfRPnGl9xuWfWn2Kerk2Y9vc8VwSDMQghqCYAMi+87Xb9mBcdxHwH4CABweHEAzeFxjtDDpL1FqHCCpTCXqGohVyQCkCNM2QFZk1/GmVUvY8PZ8zhY6li4bcW9RFUHuUIOFltoJagtDRrkZUdY/e4cNQC4YlDvDCzfuwc67RjI5GF277EVzRsH34dvPnwNE+a/hWPbN9o9CNATwhQJkMpkbTqzmm06ppzhL7FPex8w9kTO3fvcQShhFhMhBPUYgEzGWDcYhXQ8gMcFWDcg8HWiqb2xFObukxYha9rbVj/vN/llnFs2Dz+snmu+NmjmEpwta0b3SYss7oyFMiYcR5c+a3cdANA1N2JdIXP5uxs0cwlUdc22L0dFVQ2SE+PM37e0tGDDjrug7NjFrjDZiuY3S1+BrOI8Dn7xCS4d24mFjxnXMh0EOGjkeHAcx8tr0tbXoFlVDE2NOqC8Lnc/YIT4IAKEFWYx4S2oHMfpGGOzAOyEsWzqE47jzvG2LEDwZaIpUFDVNVsJ5vkr5dDpOZze8CK6T1qEElUtDBfLIJMy9O6cYr4vRplqJczurm/i29entbl+buc61F062+Ze0x+sSTTH9Vdg9ZKjeP/xHpi5aQOeGBiHpGjjESemgwBNdaz2vCZ7W3NdnQrlG1+y8kh1dSp0j2nB0W0bcPOIxwJiS2v7u7L8gLG029373EEoYRYbQWKoHMdtA7BNiLWIwEen5xCZ3AlyRQKypr2J8sXzEZncCY0VV12/mCfdbh6GY4UH2lw3/cGaRDNSV4cJfWQ4drEWCtaIVUf1+OycdXlTxNV9kDSq8X9j0vDkqqXIuuN+dMgwng/lqDLAkrrqKqx5YTyW5KXh2YLNqFVXofjMIRz8coV5eIs/Yvu7svyAsRQ5d+9zhZDCLDbUKUW4zaFlC9HS1AitptZqe3+tQo0sJ68Li4hE8Yo50GrUkChjzdeVMeFOn2fa6ps8XBO2nq4lUYkdAH0Llv5lMp7423vmP0jLc6gMBgPqq1VQRknQMb4Wn8/ojcc31uCJNzZa/QGbDgPsGNaAMTfoseX9lzHt9ZVWz3MW97P0uvK61+GjneuRmQCcdDK8xR8SM9ZndrWiKD1k9R7dvc8VQgmzP0CCGsA4ii2aYpd8UcaE49yyeebv61W1SBv/jzaCVvL6NKfrDJ72CgDg3LJ5uLBmrpXt1nFXa9tNW32Th2vClacbIQWqfj5h9QdpeQ6VSSjttaqa7jd5TS8+okCTuhh/vD0KX316FIvnTMBTL78PRVyC07ifrdeV112H1f9txuvDY/HMVo1DL9WbxIzQImx7Zhff+1whlDD7AySoAYyj2KKlCPLBVpS7T1qErG4dPF7HnmdboqpFxsTXzMJsGXeNvO/vMDAp9AYDmn/+DVqdHo3NWgAMkeHO/8m21NciimvE6KwY7N3zud1tozt/wCavKVJXh/AIIEUhw+ieDJ+ePGYWQ2dxP0uvS6/XI0JXg0n95PjuihaP9w3DhxZeqkkQR81Y4FViJtCz40IJsz9AgkrwRiJhViJ+TVULuSIBYRHGU1FbmhqR8dQ7aKy4ahbk8sXzodO3Vs9Zxl0BoOtT7+DiJ3MhT+wIaVQMStf+BZxeB7lMag4dhEm4Nh8ejXU1GN9bjpfuTcTZNRV2RcadP+CfTx7C8dIGLN9nDA1IGFCpaUHXOIbj29ch+54Hncb9zh/bhwMXSrD+VAOaGzTQNmnQIVqC9FgOy8bGYl1hrZUwy8oK8c3SVzxOzARLdjxY4HcAD0EASEuMwYU1c81f/bslIyVCj3hocG7ZPGg1ajRWXIVMaj2DVKvTofBiGQovlqFFp0dt2VU01anRrKm2uq/LxNfQbeoipI2dj6Gz30S6MhYX1sxF3bZXrOKwer0e4fp6PPg7GUorqnBnFzkKd38GTY3a4/c04801GDhiIp6+qzN2zxuAZeNS0TVeivyRkQjX1WHzewscxv0AoPfNd6GLMhoDR0yENDoeo3qFIzma4a+5Eais1+HurlKc2rfFLIhvjkmD6qejuP93xmaQCTlx+OnAZpe2W3vJ7T9hi7CGPFRCcNwNFXBgxux/sw4yjoNEJoc0OgH6ejUam7XguLb9H+evGBsOLEMHprhu7OWDGK4/iLTOCWiqKMbzdyVh76Uyr7fCptDA+lNXoFaVYWIfGRIjGUb1lGLlmeNYX55sN2xw84jHrLzG2MQO2HqpBslyHcZ/DShiogFEI7FDJ7MgdgxrwIQ+Muw+V4Ued6W7lZgJpux4sECCSrid3LJNUlle58d14WTM3AfPZGFgYZG4tmoe5DJjf75WY/TWopUdkXU90WVZkqW+WIiNtc3YeLYUWk0d0pUM5bU6lB3Yjl/P/uBx0sYUGtj+ydv45dvl+MuQWCijJfhzrgG7LtWix9CH7CaW9qxfarV1L4wfBEmTGkvyovFsQb25msBUVrXwsTg0qa/i/htkmLy5DKvO6MwzD5wlZoIpOx4skKAGMEIJnKPk1u5/TjV7gteq6mAwGIVPwumRlpxgfpY3FQVhEZEo/+zvqI1NglanBweASWVgYVEAjAOZU8e9AtSWoe9179b0Xk1iaku/yS+b/9vUzdXcosXgeSt5JW1O7f8Go7tKUVmvQ2W98drdXaXYsm9LG0G15zWu+sDYOGAbG7USxOhuSAYwuVKForQH3bIzmLLjwQIJagAjRGmUMwxMahZaw8Uyc+lS8Yo5yJr2JgDHFQWDZi5B4WUVDAYOOm0Lrrz2e+MPOEAulyItMQaNMimGzn4ThRfLoIcEBoNx/mjp2vkoXvIkwBkgl0khSTQOBlHGhNv1pJ1R19CM+rLLmD0sGe8d8G47nNihE3aUGrBjG6DT61GtrkZCQjwS0zq1udfWawSAGGgwuofxPVhuy/kKYjBlx4MFElTCJxReKIX2+j8vJmsdVsLpWwA9hwtr5lrVoCqSO5r/uyahA4bOftNct2oKSZiK/MsXzwcAcxWBM1ZtPYypOZH44VIN8rorkP/co5j17udebf0Bi2lVwybZFT1bkdTU1eGRTCmi0AjAeltOghh8kKASbqHV6YFmLbQ15WiqU+Pbd4yeqb6hGt0nLWqz9TcwKVLGvYowZYbVOr99MhuGploArSELU5mVCVuhtAxJ2HrKzrqwLEcr7r3QBHV9A1Bd6XXrpzslSrYi+eH8SdhRegU7vgaMo4KN0LY8OCFBJQC0FtZbojcYcP5KOXp3TjHGOGVhAMdBqkhExyffAQA0l19CVmZHj5oJ9AaDlXeq12qhr6mE9PoMVK1GjW9fn4YwSdssv0zKzJ1SWo0aKRF6IAJQJie3CYEsWvutebTimN6ReHpDBZ7KDsPHTlo/neHNAA/yQkMLEtQQwtkYvJa1C6y8RABgEmkbkfWW0vULwLU0wNBYC44DypuMWeywiEhEJEihzJtnTj6ZsCfSli2vkuv1qI6wPda6vkGLQ8V6KMI5QQZ4jF+/CT+d/A5PLHjPquXUkzZQf+jdJ4SDBNUPEaJH394aJapaRCs7mnvrTbRmz9+0un5o2UJc2/AiJMpYlJdVAxIJOIMBsvgOaFEZT71hcCy4ldvfM59Pr9dUIeWxfxi/5wyI62ic2lS8Yo5b78cbLE9VHTf/PWx8NA2v/KcGz9ydgUmfe5agsleidG96Pb4qPNGm5dSTioJAbxslrCFB9UOE6NG3t4bhYhlUBdbXDi1biHqVMaZpSvYARs9x8LRXzIkh05DovYvnI2PKv833ORpUotdqgdoKSKNtTiKVygC91u33IQSmUxWSY+SY0D8ah3+t9bhe0zbZZJxYVY0eyeH46UDrMGpP2kCpbTT4IEEVCWdeaHvS0tSItPH/AACriU68PUepFCmPvGwUUACqLW9CFtcBOvVvMB8L6iZ8621tT1W4UtmIhIQExHiQGLKNhVpOrMo/qDK3fHoSYw2WocpEKySoIuHrSVFCYxI1fZ0aFxZPMV+XSBgkiTFtxE0qkSAsKd1cMsWkMkiun/XEJNYnk7qCb72t7akKJ38uwbL/RSN7xESv1nMUTzUYgIUTE83XnLWBUttocEKCGmI01VZir8XWvqlOjWtfvQlJWAQ6jPyj+bpWo8a5ZfPMQmkpava8a1VdMwbNXOKW+HEGvVWmXsLpUfbZ31EGmLuxAGNHlr2SLL5kZ6YD/9kLbfMjkIe79nJtE0eO4qlny/RIiu5gvuYsrEBto8EJCWoIYZr2pMxr9YJbdHqEJaZDte55qyy7swy6N941C4vCtZVzoKtVQSaVIP16zWj/bq3lTo4O8/OF1/7cA1l4a/tq3Dz2aZf32iaO7HU41alrodUDuUvc63qittHghATVDxGiR9/RGnKZ1Eo4Cy+WuRza7D0MnM54TlPqowsBAFc/+L2ViIpFz4wURO/cj6YGDSKiFA7vs5c4EqK21NEaddVVWLbg91RGFaCQoPohQoiNozVsjxwxFcqbtvgm+CbHJJweqnXPt7kuZ5zoYmpi3uh+WFiwAreOm+3wHj6JI29qTKmMKrAhQRUJSw/yWoUaBmZM1EgkzCx6QscO7WEqlHdVJO8pfbun2q9iSE7lvbZQZ2l1SklAcstZaGrUPkkceSqOVEYV+JCgioTlH357xg6FxnReFACrM6OUMeGCCrSJQTOX4PTFijZdXWERkUCdxuP1/jw2G89/tRy3TzJ605ZeJZ/EkTfi6I43TJ1V/g0JaoghdHzWdBIqYH28szcfBlZeu838VfNc1go10ia8blUzC1yvm43w+JFQxivQVa6GuqIUCcmpVl4ln8SRp6ECd71hCgn4NySoIYazLbG7W+k23rUXJ6G6ss2R1257ZLWm4jcYDAY01alRooFX4ZI5Y3Mwa91yDHjwGSuv0jRZ31Msj6BWlVzGY/07YNIm516qO94whQT8HxLUEMEdsRSj2cCeXdcq1NByDIaLZVbXbQ/5A4wtoGHKDMgUiUgdNdcs7p7YHBsdib4JLdiz4QNBOpcsj6Bu1jYiQleHUZnM6XqeHG1NnVX+CwlqiOCvnVn27CpfPB8Gnb7Ntt7R3AAhGJ/bE+9Mextv/bEHAH6dS5ZHUCdGMlQ1FiM6XolYJ6ECV6VY1FkVGJCg+gG+O/xOOBx5uNcq1Miy+N6UpLJMUAH8KxY0Fb9Br9NDbzDg2tdvms/1gywcaY//E5xeZ9eDdZfPdx/D4AwJymq1SIqW8+pcmvHmmja9/u6eE+UI6qwKDEhQ/QB/qct0hiMP99q/plslkrQ6PVLGvQoGDgaZ8Z+XTMqg2vkvXs83GAwIS+wIaXQ80sa0ts5eXfc3qNbNR7RCYTUr1VP2nShCSQ3DI8t/RVJiq8fnTeeSL7xJ6qwKDEhQCV6kJcaYy6O6T1qE8iYp4tK6WN3TWHEVEg/XZfJwq4lXTXVqSCNjEa1QWHV6XZNIMHT2m/aWcAtVtQYz3liDFS89haS4aKzafQZFyfeiS9ZAr9f0hTdJk/8DAxJUwoyz0IOnp43yJfWBP1kJ597F8+1O9ZdIGK9wyaqth6EuLcbKgkOYO/FeTLq7D55cspGXoPrCm6T608CABDXA8LZLyJ04rbPX27asCoU9u/R1apR99nfz8dGAsWnAXozU0kN2F5NX+vyk+7Bo3S5smtwBf/vPMTyZNxhJcdF4KKcDvj9+AD0G3unVe/KFN0n1p4EBCWqA4W223l/jtK7ssvwAKf36LZRev246UcAbTF7pzH+tRoZCj8MXG5HXQ2b2Usfe3gtf5W/BDTm5YMz7RJdQUP1p4ECCSriFu5UIpmOdLdFq1OjfLdmr55o+QCQ2p7Je2/Ci1bxWt9e7frT0u3kJGP1JMdY8osBLe2vxwaMd8YeCVi918h1dUHBoG2684wGv7BYSqj8NHEhQCbdwx8NVxoQb++ltWkDtHfHsKbYZfG+HuZjOl4pCPSb2k+NosQ55mTIU/Kix8lL7d0vB76e/hk433oLYRCUv2/lA9aeBBS9BZYw9CuBlAL0BDOI47gchjCICE3dEU6hJUd5g8k7XPqxAZUUdpg6Q4/61DXj17kj8bY8asTEKdC4rwtyJ92LV1sNQSurwVf5LmPzS+z61yxntUX9KCS/h4OuhngXwEIAPBbCFCAHE7NgyeadM1wilQgZwHEb3kmPjeYZZuclA+kDMnXhvq/A+3gHDPj6EalU54pXe17jyoT3qTynhJRy8BJXjuPMA/CJw7y/42gMLhK4qf8V0+um7B+qg1xlg4AxIjGQor9fiokZu5Z3m9ZCgV0o4JvSNxFfv/Q1TXl0uis2+rj+lhJewUAxVYHztgflrtt5XCPkBYnn66aK13wIlxzH3zjgsOlDTxjv9bJyxZOsvd8Uhe/EPqCq/hsSUNO/fiJ8iZMKLQgdw3cDCGNvNGDtr52uMJw9ijE1njP3AGPvho68PeW8xQfDEJJqTc6IBAJNzolGw/xgqa+rN3qlSYfQ1lAoZnsyOwOZ3/+pTm0xnSWlq1D59ju0zfzqwGRNyWhNePx3Y7LUNlqGDUMWlh8px3D1CPIjjuI8AfAQAOLyYc343QRjxhcdvTzTzekjw/qa9WL7lv+D0Wqw53QSJpDWUVd38ExrqahEVE+v1c50hRhxTyIQXhQ6M0Jaf4IU7MWPLe65VqM1DoiUShrTr3VC2W3jTa0pUtVZzUS1PBfAWUyx1XWG51XUddwJREj3io6R4dORgzJ14r/lnpZW1+FvBx7htwhzb5XgjlhgJmfCiWlkjfMumHgSwGEAygK2MsVMcx90niGVEQOCOB2l5T5bNPY5qSU2vKV8832ouqhAzUS1jqebnVWswdu47UBg4LMiV4429R81F/gCQmhSLjjiD2iqV4HWpYomRUAkvqpVthW+WfzOAzQLZEhRQFt455y06nq6pjDNTr1WoAanM7K0CQImqFtXLFrpcT6iqilVbDyNZ3oTcrnJkp8kwpGOLucjfxLwxOZizaRkGT37B7XVdEQxiRLNaW6Etv8CEWhbeU3R6zuxxyhUJyJr2JsqvT5KyPJvKcLEMqoK2nq8tQsRYVdUafPmfI5A2N2Ny/2jERTKM7KbFX2y81ITYKGRG1aOytARJqelWa9RVV2H1P/8EBoYnFrznthgGgxjRrNZWSFAJwTl/pRwlqtaJ/aY4qDcT9W1nA2g1akiUsV57/KZJUx+98IRZKC29U2W0sfCla4LUrpf6p9E5eGbNcuROtfaej23fiPqLJxEXIfFIDINBjGhWayskqITg6PSc2fsEYI6DehP/tJ0o5Szu6g62808BY5Lq2JUmHL1iwNvfNZnvlUolGFBfZCWoiqhw5CRzKL38C1K7GM+fqquuwrk9m5AUyeHFXBle3LfJ7S27pRhRHWfgQ4JK8MJezPiaqhbRyo7m701eplZjrG+UKxLM1x0hkzJoNeo2a/OJRZvqT5c+pMRMi8lS9pJUzpj5wAA8vfxTpE7/BwCjd9oprBZ3dZNjQJoUw9O9SyxRC2jgQ4JK8MJezLj7pEXIsvAsTV6mSRxNnqszendOgcHLiVKOsGwpzevR1GY77y7hYXIM6RaB4qJCxKWk49yeTYhtacAT/RWIj2QY002LWR54qQDVcQYLJKhEu+LuhH7Tvd6sZ++1ti2lk3OiMe6zY1ZJJ0+YMrwfnvpgDXRxXc3eaWv8VeKxl0p1nMEBCSrRrghdBeHueo66o7z1UmUyKfL6JGHhmm2oulqPU1f0ePe7RvPPmUSKNI17iaVgKJ0ijJCghgjtOYfUH2txHXVHdSwr8kpQAWDckBtRUFiB3KVbeE1cE7t0ipJhwkGCGiK0xxxSvqLtS9H3NPHkDowxTLglHXuO7EavW4d7vY7YpVOUDBMOElRCMPiKtpjDp71lxM098Hn+ThgGDYNE4nJ4m13ErOOkZJiwkKASdvF1iMDe+qZ2U29PMxUDxhimDu2Oz/dvQd+hY8U2x2MoGSYsJKiEXTz1FgfNXIISVS3KF8+3uh4WEYl4N9d3t93U38jt0wUr9++BLvcByGRysc1xG6GSYRSDbYUElXDJoWUL0dJkzGBrNa0tpaYkk2nMXtIjryAs0VTQzxAZLjO2jUbYWzW4ePbeXli2ayOyR0wS2xS3ESoZRjHYVkhQQwQ+mfeWpkZkPPUOAOP4PNMQk9ZCfeOYPSaRgsnCAACcrkUo0wOC7Mx04D97oW1+FPLwwJgsJkQyjGKw1pCghgjtMQVLIpGgRVUMAOAMekAmhVajhjI52a3X+6LdtD157oEs/HvbKgx6cJrYpriFEMkwisFaQ4JKOOXQsoVoqlOjtszoxXAGPQodTI5SJLf27zdWXEXfbh0gUca6Lea+aDflg73JVM7omZECxc79aGrQICJK0Q4Wigs1JLSFBDVAaa/jqutVtZBGxkIeb5pVaoyNNlZcdX3Coxvr27vuL9ibTOWKeaP7YWHBCtw6braPrRMfsRsS/BES1AClvY6r7j5pEcqbpIgMd5699nRuqb8P4nY0mcry5/a8104pCUhuOQtNjTrovTSxGxL8ERJUwiW2YgkYBbN/N2Ns9NyyecbSKItsvjI5gr5i9AAAEW5JREFU2e9F0xnOJlOpqjW494/vIo412PVe/zw2G89/tRy3T3peDNPbDRos3RYSVMIl9grtzy2bJ7hgtue8AWe4mkz1/qZ9qFVX4tURkXjT5pgUAFDGK9BVroa6ohQJyantZjchPnzCYAQhKKYwhu2XPZF1uk61Bg//9QNU1tR7ZYezyVSqag3W7zyMx7Jk6BbHITfN6L3aMmdsDs5tXe7V84nAhTxUwiliJI8sT0YFWk9HdddT9SaZZImzyVSaxhaE6Zswqmc4MuIkuL+rHgvseKmx0ZHoE9+CiqsXkdypm8c2EIEJCWqA0l5CJ0Yc1PJkVKD1dFR3Em6ukknu4Ggylapag9xp/8TDvaToGi9BdBhDlzhm9lJtxXvWqGzMWPEpkp8OnNkEBD9IUAMUf0n4+Evc04RQx5w4WltmaMHKU1psK9JBwgCtgYOqAehXe77NcyLDw3BrJxlKfj2P9Bt6C2ID4d+QoBK88KeRe0Ifc2LLvhNFqNdL8UgWw7SBrTuBFad0SOtnXzCn3d8fUz9chfQbXuf9fML/IUEl/AZTGOOaqtZ8Mirg/HRUS4Q+5sSWLW/Pwuh5+ThYpsLBbZY/kaGjzv7kf7lMiuG9YlF07ji6ZA3kbQPh35CgEn6DZTOBOyej2uLqmBNPW0nt4c3k/0l398GT+RvQ+cYcXkelEP4PCSrhd3ibcHMldnyz/94ikUjw0MBUfH/iIHoMvLPdnku0PySohN/hi2SWp9l/IbxZS8be3gtf5W/BDTm55KUGMSSoBC8CYcgJ4Hn2X2hvljGGyXd0QcGhbbjxjgd4r0f4JySoBC/8pXzLGZ5m/4WoZbXHsOzuWLt4Dwy33Q+JVMp7PcL/oNZTIuhxlv13dr/Rm3V8nzf84Z5MFO75UrD1CP+CBJUIevadKMK6wmbctKTc/LWusBn7ThS1udfknU7OMXqkk3OiUbD/mNdzAWwZ1DsDLRe/h04bWkfEhAqM4zjXdwnN4cUiPJQgXLNo7bdAyXHMvTOu9dqBGiB9oGCVAWcvliL/lBQDR00RZD2ifZl2Z3eHWUWKoYYIQraI+lu7qZC4qmUVgj7dUiHftQ/NjQ0Ij4wSZE3CP+AlqIyxfwMYBaAFwK8AnuI4rloIwwhhEbJF1J/aTYXGm8J9b5g3qi9e2/YpBj38TLs8j2gf+MZQdwHow3FcPwBFAF7gbxJBBD9d05IQX38ZDXW1YptCCAgvQeU47luO43TXv/0eQCdn9xME0cq8MQNwuuBjsc0gBETILP9UANsd/ZAxNp0x9gNj7IePvhauDIUgApXUpFh0RDlqq1S81qmrrsKyBb+HpkYtkGWEt7gUVMbYbsbYWTtfYyzuWQBAB2Cto3U4jvuI47ibOI67afqYwcJYTxABzrwxOSgsWMZrjWPbN0JWVoij2zYIZBXhLS6TUhzH3ePs54yxKQDyAAzjRKnBItxByBbRQGk3DQQSYqOQGVWPytISJKWme/z6uuoq/HRgM5Y8mI5nCzZj0MjxQX98tT/Dqw6VMXY/gEUAhnAcV+H2C6kOlSDM1Dc2Y+bqQuROXejxa/esX4qe1zZjVq4S+QdVKEp7EHdPmOkDKwkTzupQ+cZQ8wHEANjFGDvFGPuA53oEEXJER4ZjYAqH0su/ePQ6k3c6IcfYhDAhJw4/HdhMsVQR4Zvl78FxXAbHcQOuf/1BKMMIIpT4w8gBKPp2pUevObZ9I0ZlAknRcgDG/x2VCYqligh1ShGiEMzdVt4QHibHkK7huFJ0Bhk9+7n1mp9PHsLJ8iZsPHPV6rqi9BBt+0WCBJXwGc5EM5i7rbxlyvB+eOqDtW4L6ow31/jYIsJTSFAJn0Gi6RkymRR5fZJw6vR36N7/NrHNIbyAxvcRhB8xbsiNuHr4S1AFYmBCgkoQfgRjDOMHpaPoyG6xTSG8gASVIPyMkYN6QHVyBwwGg9imEB5CMVRCFKjbyjGMMfx+6A34fP8W9B06VmxzCA8gQSV8hjPRDMXSKE/I7dMFK/fvgT43D1IZ/ZkGCnQECkH4KSd/LsGy/0Uhe8QksU0hLPBl6ylBED4iOzMdKDkFbXPbWl7CPyFBJQg/5rkHsnBy2yqxzSDchASVIPyYnhkpUNT8jKYGjdimEG5AgkoQfs680f1wqmCF2GYQbkCCShB+TqeUBCS3lNBYvgCABJUgAoB5YwbgzDfLxTaDcAEJKkEEAMkJMegqV0NdUSq2KYQTSFAJQkRU1Ro8/NcPUFlT7/LeOWNzcG4rean+DAkqQYjIqq2HoS4txsoC10erx0ZHok98CyquXmwHywhvIEElCJFQVWtQsP8Ylj6kRMH+Y255qbNGZeN/Oz71vXGEV5CgEoRIrNp6GHk9JOiVEo68HhK3vNTI8DDcki5Fya/n28FCwlNIUAnCRziLj5q808k50QCAyTnRbnup00cMwIXdqwW3l+APCSpB+Ahn8VGTd6pUGCdJKRUyt71UuUyKe3rF4PK544LbTPCDBJUgfICr+Oi+E0VYV9iMm5aUm7/WFTZj34kit9afdHcfXD6w0RemEzygQYsE4QOs46NNWFlwCHMn3mv++Za3Z/FaXyKR4KGcDvj++AH0GHgnX3MJgSAPlSAExl589Os9R5E3L9+tGKm7jL29F0qPbqED/fwIElSCsMCTQntH2IuPDklvwa8XLrsVI3UXxhgm39EF5w9tE2xNgh8kqARhgSeF9o6wjY/mLC7Dih/qkB4rcTuT7y7DsrujpnAPDHq9YGsS3kNHoBDEdVTVGoyb/x6W5kVhZkEDPv/3c0iKi+a97qK13wIlxzH3zjgsOlADpA+0iqfy5cj5Yqy+lIT+wx8VbE3CMXQECkG4gTeF9q7gU2/qLrf0zoD20hHotC2CrUl4BwkqQcB3wsen3tQT/nj/73B6xzpB1yQ8h8qmCALOhY/P9nzfiSL8Vt6MdYXlVtc7lhUJuu3P6pYG+a59aG5sQHhklGDrEp5BMVSCADB6Xj5+K1e1ud4xRcm7ZrS9uHStEq8d0GDQw8+IbUpQ4yyGSh4qQYB/ob0/0DUtCXGas2ioq0VUTKzY5oQkFEMliCDiz2OzcbrgY7HNCFlIUAkiiEhNikU6K0dtVdvwBeF7eAkqY+xVxtgZxtgpxti3jLGOQhlGEIR3zB2dgzPfLBPbjJCEr4f6b47j+nEcNwBAAYCXBLCJIAgeJMRGoWd0PSpLS8Q2JeTglZTiOK7W4ttoAJS9Jzxm0MwlUNU1t7mujAnH0aXPimBR4PPcmBzMXL0cuVMXim1KSME7y88Yew3AZAA1AIY6uW86gOkA8OH8xzB9zGC+jyaCBFVdM7Kmvd3m+rll80SwJjiIjgxHTjKH0su/ILVLD7HNCRlcbvkZY7sZY2ftfI0BAI7jFnAclwFgLQCHtSccx33EcdxNHMfdRGJKEL5n5gMDULTzU7HNCClceqgcx93j5lprAWwDQHsMgvADwsPkGNItAsVFhejUs6/Y5oQEfLP8mRbfjgHwP37mEAQhJFOG98OFPWvENiNk4Jvlf+P69v8MgHsB/EkAmwiCEAiZTIq8Pkm4cPo7sU0JCfhm+R8WyhAidFHGhNtNQCljwkWwJvgYN+RGFOR/iW79bgVjDtvQCQGgXn5CdKg0yrcwxjDhlnTsObIbvW4dLrY5QQ21nhJECDDi5h5QndwBg8EgtilBDQkqQYQAjDH8fugNOLd/i9imBDUkqAQRIuT26YKGooPQ6bRimxK0kKASRAjx7L29ULhro9hmBC0kqAQRQmRnpgMlp6Btbjs7geAPCSpBhBjPPZCFk9tWiW1GUEKCShAhRs+MFChqfkZTg0ZsU4IOElSCCEHmje6Hk998IrYZQQcJKkGEIJ1SEpCi/Q2aGrXYpgQVJKgEEaLMGzMAZ75ZLrYZQQUJKkGEKMkJMegqV0NdUSq2KUEDCSpBhDBzxubg3FbyUoWCBJUgQpjY6EhkxbegouSS2KYEBSSoBBHizB6Vjf9tXyG2GUEBCSpBhDiR4WG4JV2Ckl/Pi21KwEOCShAEpo/Ixq+7qXuKLySoBEFALpNieK9YXD53XGxTAhoSVIIgAACT7u6Dywc2guM4sU0JWEhQCYIAAEgkEjyU0wG/njgotikBCwkqQRBmxt7eC9eObCEv1UtIUAmCMMMYw5O5XXD+0DaxTQlISFAJgrBiWHZ31BTugUGvF9uUgIMElSCINvzhnkwU7vlSbDMCDhJUgiDaMKh3Bloufg+dtkVsUwIKElSCIOzyxxE34vSOdWKbEVCQoBIEYZc+3VIhrziH5sYGsU0JGEhQCYJwyLxRfXF626dimxEwkKASBOGQrmlJiNNcQkNdrdimBAQkqARBOOXPY7Nxio5KcQsSVIIgnJKaFItOkgrUVqnENsXvIUElCMIlc0fnoLBgmdhm+D0kqARBuCQhNgqZUfWoLC0R2xS/hgSVIAi3eG5MDn7cRrFUZwgiqIyxeYwxjjGmFGI9giD8j+jIcAxM4VB6+RexTfFbeAsqYywDwL0ArvA3hyAIf+YPIwegaOenYpvhtwjhob4DYD4AGqBIEEFOeJgcQ7pFoLjojNim+CW8BJUxNub/t3cvoXHVYRjGn9ekXqiKoF3UJlAXRZRaLJTgQkTQapBi7ELwsikuQhdiXRQsLVhUuhBBBFcWWlAYvEAUXVSo2oIXjDaWRGvTllCVtl4KStHgQmJfF3MCSWaSGeNx/ufkfD8YmDOZTB5mmI9zmTkBztkey6knhFBwWzau47tDtdQZhdRyoEr6UNKxJpcBYCfwdDt/SNKgpBFJI3vf/ey/docQEunu7mLT2ms5PfZ56pTC0WL/1YGkW4CPgOkzJ/QAPwJ9tn9e8JfH3ozdAyGUmG121Ia57ZHtqVM6bvP6Hs33s0UP1IYHkr4HNtgu1NcpJA3a3pu6o5UydEZjfsrQWYZGKFZnFT6HOpg6oE1l6IzG/JShswyNUKDO7rweyPbqvB4rhBDKqAprqCGE0BFVGKiF2LfShjJ0RmN+ytBZhkYoUGduB6VCCKHqqrCGGkIIHVGJgSrpOUlfSxqVdFDS9amb5pL0gqQTWec7kq5J3dSMpAclfSvpoqQNqXtmktQv6aSkCUk7Uvc0I2m/pPOSjqVumY+kXkmHJR3PXuttqZvmknS5pC8ljWWNz6Rugops8ku62vbv2fUngJttb02cNYuke4BDtqckPQ9g+6nEWQ0k3QRcBF4BttseSZwEgKQu4BSwETgLHAEetn08adgcku4AJoHXbK9N3dOMpJXASttHJV0FfAU8UKTnUpKA5bYnJS0DPgW22R5O2VWJNdTpYZpZTgFP5GL7oO2pbHGY+jfPCsf2uO2TqTua6AMmbJ+2/RfwBjCQuKmB7Y+B31J3LMT2T7aPZtf/AMaBVWmrZnPdZLa4LLskf19XYqACSNoj6QzwKG2efyChx4D3U0eUzCrgzIzlsxRsCJSRpNXAeuCLtCWNJHVJGgXOAx/YTt64ZAZqi5O4YHuX7V6gBjxexMbsPruAqawziXY6w9In6UpgCHhyzlZeIdj+2/at1Lfm+iQl34WS2zelUrN9d5t3rQEHgN3/Y05TrRolbQE2AXc54c7tf/FcFsk5oHfGck92W1iEbL/kEFCz/XbqnoXYviDpMNAPJD3Yt2TWUBciac2MxQHgRKqW+Ujqp36i7vtt/9nq/qHBEWCNpBskXQo8BLyXuKmUsgM++4Bx2y+m7mlG0orpT8JIuoL6wcjk7+uqHOUfAm6kfnT6B2Cr7UKtvUiaAC4Dfs1uGi7aJxEAJG0GXgZWABeAUdv3pq2qk3Qf8BLQBey3vSdxUgNJrwN3AtcBvwC7be9LGjWHpNuBT4BvqL9nAHbaPpCuajZJ64BXqb/WlwBv2X42bVVFBmoIIXRCJTb5QwihE2KghhBCTmKghhBCTmKghhBCTmKghhBCTmKghhBCTmKghhBCTmKghhBCTv4BR6HzxtDzLf0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "40c30e638b6defe125180b9832a675e2",
          "grade": false,
          "grade_id": "cell-b1bde9222e35b3fc",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "ds316jYbo3AX"
      },
      "source": [
        "1) Why does the Perceptron (`model1`) only achieve about 50% accuracy? \n",
        "\n",
        "2) What is the architectural property of the Multi-Layer Perceptron that allows it to more accurately learn the relationship between X and y? \n",
        "- Hint: recall that each layer represents a vector space and they usually have a different number of dimensions, $\\mathbb{R}^N$.\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e01b50ff508342b905c5a4cdbd7d2dc4",
          "grade": true,
          "grade_id": "cell-302694c508c8da0e",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "V-ihs6aGo3AY"
      },
      "source": [
        "The perceptron model - because it is not learning with backpropagation\n",
        "The MLP is using backpropagation to fine tune the weights and biases\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynxzzyudXetM"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCJo5znVo3AY"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "- Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
        "- Train your model and report its baseline accuracy. \n",
        "- Then `hyper-parameters tune two parameters each with no more than 2 values each`\n",
        "    - Due to limited computational resources on CodeGrade `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE`\n",
        "- Report your optimized model's accuracy\n",
        "- Use the Heart Disease Dataset provided (binary classification)\n",
        "- Use an appropriate loss function for a binary classification task\n",
        "- Use an appropriate activation function on the final layer of your network.\n",
        "- Train your model using verbose output for ease of grading.\n",
        "- Use GridSearchCV to hyper-parameters tune your model. \n",
        "    - **Use `n_jobs` = 1**\n",
        "- When hyper-parameters tuning, show you work by adding code cells for each new experiment.\n",
        "- Report the accuracy for each combination of hyper-parameters as you test them so that we can easily see which resulted in the highest accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "NslMkpGfo3AY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "5d17bddf-fc56-414c-8763-a556f31ea3c0"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# load data\n",
        "data_path = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv'\n",
        "df1 = pd.read_csv(data_path)\n",
        "df1 = df1.sample(frac=1)\n",
        "print(df1.shape)\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>152</td>\n",
              "      <td>277</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>132</td>\n",
              "      <td>207</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>214</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>246</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "127   67    0   2       152   277    0  ...      0      0.0      2   1     2       1\n",
              "91    57    1   0       132   207    0  ...      1      0.0      2   0     3       1\n",
              "116   41    1   2       130   214    0  ...      0      2.0      1   0     2       1\n",
              "233   64    1   0       120   246    0  ...      1      2.2      0   1     2       0\n",
              "302   57    0   1       130   236    0  ...      0      0.0      1   1     2       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbdYGX05W7BQ"
      },
      "source": [
        "df = df1.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQHcms34o3AZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cff9d58-6519-4627-f635-e5ea5b60ea02"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "22de1dc5d17d7a0bc674d082c33e8b65",
          "grade": false,
          "grade_id": "cell-85dc40f19f5a1d6b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "oPAdng0po3AZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dd058f5-67f1-4050-86e7-d7f2b1d3ffa2"
      },
      "source": [
        "# Create an input matrix named 'X' store it in a 2D numpy array\n",
        "X = df[:,0:13]\n",
        "y = df[:,13]\n",
        "# Create an output vector for the labels named 'Y', store it in 1D numpy array\n",
        "\n",
        "\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(1, kernel_initializer='normal'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\treturn model\n",
        "\n",
        "#evaluate\n",
        "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10)\n",
        "results = cross_val_score(estimator, X, y, cv=kfold)\n",
        "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline: -0.15 (0.04) MSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FQx01TVbTwC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "825d4f808810a2a8d6301d7453afe478",
          "grade": true,
          "grade_id": "cell-c17c686c974edc2e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Z1-jpK_Mo3AZ"
      },
      "source": [
        "# Visible Testing\n",
        "assert X.shape[0] == 303, \"Did you drop/lose some rows in X? Did you properly load and split the data?\"\n",
        "assert X.shape[1] == 13, \"Did you drop/lose some columns in X? Did you properly load and split the data?\"\n",
        "assert len(y)== 303, \"Did you drop/lose some rows in Y? Did you properly load and split the data?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgePf3Yao3AZ"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "475835631ff6a34028443dbf604bd922",
          "grade": false,
          "grade_id": "cell-cfc5517cd0b6fa64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "jmlTumeNo3AZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c35926-eaec-4ce4-f3a3-cbda0ddc0983"
      },
      "source": [
        "# Create a function named 'create_model' that returns a complied keras model -  required for KerasClassifier\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "def create_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(26, input_dim=13, activation='relu'))\n",
        "\tmodel.add(Dense(2, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "estimator = KerasClassifier(build_fn=create_model, epochs=100, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(estimator, X, y, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline: 76.61% (9.46%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b906697afb0a3b52cd19e9548eae6a7",
          "grade": true,
          "grade_id": "cell-fac25126eaf1eee4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "lH2wJdvLo3Aa"
      },
      "source": [
        "# Visible Testing\n",
        "assert create_model().__module__ == 'tensorflow.python.keras.engine.sequential', \"create_model should return a keras model that was created using the Sequential class.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0412c74b7803790452d4914d99995dd2",
          "grade": false,
          "grade_id": "cell-fbc3d0a07230078c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "XfHsoS-mo3Aa"
      },
      "source": [
        "# Pass 'create_model' into KerasClassifier, store KerasClassifier to a variable named 'model'\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=5, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0442c29a94065e922c5ae929976a52ab",
          "grade": true,
          "grade_id": "cell-464e7506993775f2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4Ot-SVbgo3Aa"
      },
      "source": [
        "# Visible Testing\n",
        "assert model.__module__ == 'tensorflow.python.keras.wrappers.scikit_learn', \"model should be a instance of KerasClassifier.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f88603ef37a4d3d2ef8699a41ac9a0b2",
          "grade": false,
          "grade_id": "cell-985c0425f3b1304d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "lGEncVvqo3Aa"
      },
      "source": [
        "# Define the grid search parameters inside a dictionary named 'param_grid' \n",
        "# Use 2 hyper-parameters with 2 possible values for each \n",
        "\n",
        "param_grid = dict(epochs=[10,20,30], batch_size=[10,20,40])\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a551fd8278b30c1318c036f6ad43b503",
          "grade": true,
          "grade_id": "cell-c765b5db5489d7a2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "USqiu-Q4o3Ab"
      },
      "source": [
        "assert len(param_grid.keys()) == 2, \"Did you create a param dict with 2 hyper-parameters as keys?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2ea6312f4bc1f42809196b696037dd52",
          "grade": false,
          "grade_id": "cell-7cfb4315eab5031c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "CXrGZIuDo3Ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b254231-7cbf-47e9-b662-60dc8ab76c16"
      },
      "source": [
        "# Create Grid Search object and name it 'gs'\n",
        "# Run Grid Search \n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.798680 using {'batch_size': 10, 'epochs': 30}\n",
            "0.679868 (0.032672) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.702970 (0.070011) with: {'batch_size': 10, 'epochs': 20}\n",
            "0.798680 (0.033657) with: {'batch_size': 10, 'epochs': 30}\n",
            "0.567657 (0.102363) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.712871 (0.045011) with: {'batch_size': 20, 'epochs': 20}\n",
            "0.660066 (0.028391) with: {'batch_size': 20, 'epochs': 30}\n",
            "0.514852 (0.035238) with: {'batch_size': 40, 'epochs': 10}\n",
            "0.663366 (0.058295) with: {'batch_size': 40, 'epochs': 20}\n",
            "0.646865 (0.044524) with: {'batch_size': 40, 'epochs': 30}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHX1p4yHo3Ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1df736df-8c9c-4576-920a-4e2b9ed2f051"
      },
      "source": [
        "# your grid_result object should be able to run in this code \n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.7986798683802286 using {'batch_size': 10, 'epochs': 30}\n",
            "Means: 0.6798680027325948, Stdev: 0.03267161881186689 with: {'batch_size': 10, 'epochs': 10}\n",
            "Means: 0.702970286210378, Stdev: 0.0700105796278302 with: {'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.7986798683802286, Stdev: 0.0336568844486241 with: {'batch_size': 10, 'epochs': 30}\n",
            "Means: 0.5676567554473877, Stdev: 0.10236344535014313 with: {'batch_size': 20, 'epochs': 10}\n",
            "Means: 0.7128712932268778, Stdev: 0.045010509088070284 with: {'batch_size': 20, 'epochs': 20}\n",
            "Means: 0.6600659886995951, Stdev: 0.028390503971451875 with: {'batch_size': 20, 'epochs': 30}\n",
            "Means: 0.5148515005906423, Stdev: 0.0352378854744143 with: {'batch_size': 40, 'epochs': 10}\n",
            "Means: 0.6633663376172384, Stdev: 0.05829546088508044 with: {'batch_size': 40, 'epochs': 20}\n",
            "Means: 0.646864672501882, Stdev: 0.04452387307814832 with: {'batch_size': 40, 'epochs': 30}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmP659pNo3Ab"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}